{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES:\n",
    "#To get a list of PDB that contains histones from 'text.csv':\n",
    "#cut -f1 text.tsv | uniq | awk '{print tolower($0)}' | sort\n",
    "\n",
    "#text.tsv should be sorted by pdb and then uniprot name\n",
    "#it MUST have 'NA' in uniprot and name blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python 3\n",
    "import re\n",
    "\n",
    "#PATH = \"../data/Interfaces/\"\n",
    "PATH = \"/net/pan1/interactomes/pipeline/Interactome/Workflow/Interfaces/\"\n",
    "CHAIN_FILE = \"text.tsv\"\n",
    "PDB_LIST = \"pdbList.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#fils is a string with path to the file to be checked\n",
    "\n",
    "#RESULTS:\n",
    "#Returns 1 or 0 depending on file existence \n",
    "\n",
    "\n",
    "def file_check(file):\n",
    "    \n",
    "    try:\n",
    "        open(file, \"r\")\n",
    "        return 1\n",
    "    \n",
    "    except IOError:\n",
    "        print(\"Error: \" + file + \" does not appear to exist.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#name is a string with the name of chain\n",
    "#typeCount is a 2-element list with the first one being an empty string and the second - 0 (iteger)\n",
    "\n",
    "#RESULTS:\n",
    "#Updates the typeCount array: the first element = general histone type(s); the second element = (should be) number of histones in chain\n",
    "\n",
    "def is_histone(name, typeCount):\n",
    "\n",
    "    if(not re.search(r'chaperone|ase|binding|p53 peptide|non-histone|jmjc|rna|synth', name, re.I)):\n",
    "        if(re.search(r'histone.*h?\\d|h?\\d.*histone|h?\\d.*histone-like|histone-like.*h?\\d|histone macro.*h?\\d|h?\\d.*histone macro|h?\\d.*\\speptide|\\speptide.*h?\\d|h3k4me0|h3(1-9)k4me3|$h\\d^|archaeal histone|histone peptide', name, re.I)):\n",
    "            typeCount[1] = 1 #adds the number of histones in chain  (should be changed to actual number of histones in chain!!!)\n",
    "\n",
    "            if(re.search(r'h2a', name, re.I)):\n",
    "                typeCount[0] += 'h2a#'\n",
    "                \n",
    "            elif(re.search(r'h2b', name, re.I)):\n",
    "                typeCount[0] += 'h2b#'\n",
    "                    \n",
    "            elif(re.search(r'h3', name, re.I)):\n",
    "                typeCount[0] += 'h3#'\n",
    "                    \n",
    "            elif(re.search(r'h4', name, re.I)):\n",
    "                typeCount[0] += 'h4#'\n",
    "                    \n",
    "            elif(re.search(r'h1', name, re.I)):\n",
    "                typeCount[0] += 'h1#'  \n",
    "                    \n",
    "            elif(re.search(r'h5', name, re.I)):\n",
    "                typeCount[0] += 'h5#'\n",
    "                    \n",
    "            else:\n",
    "                typeCount[0] += 'some histone#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdbList is a text file with a header and one column PDB\n",
    "#files is a list\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#A list of absolute paths to either mapping files or interface files as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_files(pdbList, files, parameter):\n",
    "    \n",
    "    with open(pdbList, 'r') as pfh:\n",
    "        pfh.readline()\n",
    "        \n",
    "        if(parameter == 'mapping'):\n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2] \n",
    "                files.append(PATH + folder + '/' + line + '_chain_protein_mapping.tab')\n",
    "                \n",
    "        elif(parameter == 'interface'): \n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2]\n",
    "                files.append(PATH + folder + '/' + line + '_atomic_contacts_5.0A.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdb is a string with pdb id\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#An absolute paths to either mapping file or interface file as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_file(pdb, parameter):\n",
    "    \n",
    "    if(parameter == 'mapping'):\n",
    "        folder = pdb[1] + pdb[2] \n",
    "        file = (PATH + folder + '/' + pdb + '_chain_protein_mapping.tab')\n",
    "        return file  \n",
    "        \n",
    "    elif(parameter == 'interface'): \n",
    "        folder = pdb[1] + pdb[2]\n",
    "        file = (PATH + folder + '/' + pdb + '_atomic_contacts_5.0A.tab')\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#cFile is tab-separated file with a header and 4 columns: pdb, chain, uniprot, name\n",
    "#dictionary is nested with the innermost dict being dictionary['pdb'] = {}\n",
    "\n",
    "#RESULTS:\n",
    "#The format of the end-product dictionary is: {pdb : {AlexChain: myChain#UNIPROT#name#type#nucleosome(bool)#bindingPartner(bool)}}\n",
    "#Example: {1alq : {'G': 'E#P02302#Histone H3.3C#H3#1#0'}}\n",
    "\n",
    "\n",
    "def get_chain_dictionaries(cFile, dictionary): \n",
    "    \n",
    "    with open(cFile, 'r') as cfh:\n",
    "        cfh.readline()\n",
    "        \n",
    "        histoneCount = {} #is used to count number of histones in a structure!!!!!!!\n",
    "        \n",
    "        tempDict = {}\n",
    "        tempDict['pdb'] = {}\n",
    "            \n",
    "        mappingFiles = [] \n",
    "        get_files(PDB_LIST, mappingFiles, 'mapping')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for file in mappingFiles:\n",
    "            try: #adds a pdb entry to the dict only if mapping file exists\n",
    "\n",
    "                with open(file, 'r') as mfh:\n",
    "                    mfh.readline() #skips header\n",
    "                    pdb = file.split('/')[-1].split('_', 1)[0]\n",
    "\n",
    "                    for mLine in mfh:\n",
    "                        chainPair = mLine.split('\\t', 2)\n",
    "                        alexChain = chainPair[0]\n",
    "                        myChain = chainPair[1]\n",
    "                        \n",
    "                        if(pdb in tempDict):\n",
    "                            tempDict[pdb][alexChain] = myChain\n",
    "                        else:\n",
    "                            tempDict[pdb] = {alexChain : myChain}\n",
    "\n",
    "            except IOError:\n",
    "                pass\n",
    "                #print(\"Error: \" + mappingFile + \" does not appear to exist.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for cLine in cfh:           \n",
    "            fields = cLine.strip().split('\\t')\n",
    "            \n",
    "            pdb = fields[0]\n",
    "    \n",
    "            if(pdb in tempDict): #continues only if a mapping file exists\n",
    "                chain = fields[1]\n",
    "                uniprot = fields[2]\n",
    "                name = fields[3]\n",
    "                #function = fields[4] !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                #organism = fields[5] !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "                histoneTypeAndCount = ['', 0]\n",
    "\n",
    "                is_histone(name, histoneTypeAndCount) #checks whether the name looks like a histone!!!!!!!!!\n",
    "\n",
    "                tempType = histoneTypeAndCount[0]\n",
    "                tempCount = histoneTypeAndCount[1]\n",
    "                \n",
    "                \n",
    "                #######################\n",
    "                if(tempCount): #if the chain is a [part of a] histone\n",
    "                    \n",
    "                    if(pdb in histoneCount):\n",
    "                        \n",
    "                        if(tempType not in histoneCount[pdb]):\n",
    "                            histoneCount[pdb].append(tempType) #!!!!!!\n",
    "\n",
    "                    else:\n",
    "                        histoneCount[pdb] = [tempType]\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                try: #adds a chain entry to the dict only if there exists a corresponding chain in the mapping file\n",
    "                    alexChain = list(tempDict[pdb].keys())[list(tempDict[pdb].values()).index(chain)]\n",
    "\n",
    "                    if(pdb in dictionary):\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + tempType #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + 'other#' #!!!!\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + tempType} #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + 'other#'} #!!!!\n",
    "                        \n",
    "                except ValueError:\n",
    "                    #print(\"Error: \" + ValueError + \", in \" + pdb)               \n",
    "                    pass\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        for structure in histoneCount:\n",
    "            partnerFlag = 0 ###\n",
    "            uniqueHistoneNum = len(histoneCount[structure])\n",
    "            \n",
    "            if(uniqueHistoneNum > 3): #checks if pdb has at least a half of nucleosome!!!!!!!\n",
    "                \n",
    "                for chain in dictionary[structure]:\n",
    "                    chainFields = dictionary[structure][chain].split('#')\n",
    "\n",
    "                    chainType = chainFields[-2]\n",
    "                    chainName = chainFields[1] + '\\t' + chainFields[2]\n",
    "\n",
    "                    dictionary[structure][chain] += '1#' #!!!!!!\n",
    "                    \n",
    "                    if(partnerFlag == 0 and chainType == 'other'):\n",
    "                        #print('\\t\\t\\t\\t\\t' + structure + '\\t' + 'nucleosome' + '\\t' + chainName)\n",
    "                        partnerFlag = 1\n",
    "                    \n",
    "                if(partnerFlag == 0):\n",
    "                    dictionary[structure][chain] += '0'\n",
    "                    print(structure + '\\t' + 'nucleosome' + '\\t' + 'no bp')\n",
    "                    \n",
    "                else:\n",
    "                    dictionary[structure][chain] += '1'\n",
    "                    print(structure + '\\t' + 'nucleosome' + '\\t' + 'yes bp')\n",
    "            \n",
    "            else: #!!!!!!\n",
    "\n",
    "                for chain in dictionary[structure]: #!!!!!\n",
    "                    chainFields = dictionary[structure][chain].split('#')\n",
    "                    \n",
    "                    chainType = chainFields[-2]\n",
    "                    chainName = chainFields[1] + '\\t' + chainFields[2]\n",
    "                    \n",
    "                    dictionary[structure][chain] += '0#' #!!!!!! \n",
    "\n",
    "                    if(partnerFlag == 0 and chainType == 'other'):\n",
    "                        #print('\\t\\t\\t\\t\\t' + structure + '\\t' + 'histone' + '\\t' + chainName)\n",
    "                        partnerFlag = 1\n",
    "\n",
    "                if(partnerFlag == 0):\n",
    "                    dictionary[structure][chain] += '0'\n",
    "                    print(structure + '\\t' + 'histone' + '\\t' + 'no bp')\n",
    "\n",
    "                else:\n",
    "                    dictionary[structure][chain] += '1'\n",
    "                    print(structure + '\\t' + 'histone' + '\\t' + 'yes bp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#interfaceFiles is a list of strings containing names of interface files\n",
    "#chainDictionary is a dictionary produced by 'get_chain_dictionaries'\n",
    "#interfaceDictonary is a nested dictionary with the innermost dict being interfaceDictionary['uniprotPair'] = {}, where the values are lists of the next form [chain pair data, residue number, pdb IDs] \n",
    "#Example: 'P84233@P62799': {'44': ['A#P84233#Histone H3.2#h3#1@B#P62799#Histone H4#h4#1$E#P84233#Histone H3.2#h3#1@F#P62799#Histone H4#h4#1', 17, '1zla$q5cl']\n",
    "#note that data fields of a chain is separated by #, @ separates chains binding partner chains, $ separates chain pairs and pdb structures\n",
    "\n",
    "\n",
    "def residue_count(interfaceFiles, chainDictionary, interfaceDictionary):\n",
    "    for file in interfaceFiles:\n",
    "        pdb = file.split('/')[-1].split('_', 1)[0] \n",
    "        \n",
    "        try:\n",
    "            with open (file, 'r') as ifh:\n",
    "                ifh.readline() #skips header\n",
    "\n",
    "                for line in ifh:\n",
    "                    lineFields = line.split('\\t', 6) #gets only the first 8 columns !!!\n",
    "\n",
    "                    chain1 = lineFields[0].split('_', 1)[0] # the split part treats biological assembly chains as separate chains ???\n",
    "                    chain2 = lineFields[4].split('_', 1)[0]\n",
    "\n",
    "                    residue1 = lineFields[2]\n",
    "                    residue2 = lineFields[5]\n",
    "\n",
    "                    uniprot1 = chainDictionary[pdb][chain1].split('#', 2)[1]\n",
    "                    uniprot2 = chainDictionary[pdb][chain2].split('#', 2)[1]\n",
    "\n",
    "                    uniprotPair1 = uniprot1 + '@' + uniprot2\n",
    "                    uniprotPair2 = uniprot2 + '@' + uniprot1\n",
    "\n",
    "                    chainPair1 = chainDictionary[pdb][chain1] + '@' + chainDictionary[pdb][chain2]\n",
    "                    chainPair2 = chainDictionary[pdb][chain2] + '@' + chainDictionary[pdb][chain1]\n",
    "\n",
    "                    if(uniprotPair1 in interfaceDictionary):\n",
    "\n",
    "                        if(residue1 in interfaceDictionary[uniprotPair1]):\n",
    "                            interfaceDictionary[uniprotPair1][residue1][1] += 1  \n",
    "\n",
    "                            if(chainPair1 not in interfaceDictionary[uniprotPair1][residue1][0]):\n",
    "                                interfaceDictionary[uniprotPair1][residue1][0] += '$' + chainPair1                       \n",
    "                                \n",
    "                                if(pdb not in interfaceDictionary[uniprotPair1][residue1][2]):\n",
    "                                    interfaceDictionary[uniprotPair1][residue1][2] += '$' + pdb\n",
    "                                   \n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair1][residue1] = [chainPair1, 1, pdb]    #format of the innermost dict        \n",
    "\n",
    "                    elif(uniprotPair2 in interfaceDictionary):\n",
    "\n",
    "                        if(residue2 in interfaceDictionary[uniprotPair2]):\n",
    "                            interfaceDictionary[uniprotPair2][residue2][1] += 1\n",
    "\n",
    "                            if(chainPair2 not in interfaceDictionary[uniprotPair2][residue2][0]):\n",
    "                                interfaceDictionary[uniprotPair2][residue2][0] += '$' + chainPair2                        \n",
    "\n",
    "                                if(pdb not in interfaceDictionary[uniprotPair2][residue2][2]):\n",
    "                                    interfaceDictionary[uniprotPair2][residue2][2] += '$' + pdb\n",
    "                                    \n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair2][residue2] = [chainPair2, 1, pdb]\n",
    "\n",
    "                    else:\n",
    "                         interfaceDictionary[uniprotPair1] = {residue1 : [chainPair1, 1, pdb]}  \n",
    "                            \n",
    "        except IOError:\n",
    "            #print(\"Error: \" + interfaceFile + \" does not appear to exist.\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_count(interfaceDictionary):\n",
    "    \n",
    "    for pair in interfaceDictionary:\n",
    "        \n",
    "        for residue in interfaceDictionary[pair]:\n",
    "            pdbCount = len(interfaceDictionary[pair][residue][2].split('$'))\n",
    "            interfaceDictionary[pair][residue].append(interfaceDictionary[pair][residue][1] / pdbCount) #[3] is normalized by uniprot pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_histones(interfaceDictionary):\n",
    "    \n",
    "    avgDict = {}\n",
    "    avgDict['type'] = {}\n",
    "\n",
    "    for pair in interfaceDictionary:\n",
    "        \n",
    "        for residue in interfaceDictionary[pair]:                           \n",
    "            targetFields = interfaceDictionary[pair][residue][0].split('@')[0].split('#')\n",
    "            sourceFields = interfaceDictionary[pair][residue][0].split('@')[-1].split('#')\n",
    "            \n",
    "            if(targetFields[-2] != 'other' and targetFields[-3] != 'other'): #MAKE ENTRIES HAVE THE SAME NUMBER OF ELEMENTS!!!\n",
    "                histoneType = targetFields[3]\n",
    "                normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                \n",
    "                if(histoneType in avgDict):\n",
    "                    \n",
    "                    if(residue in avgDict[histoneType]):\n",
    "                        avgDict[histoneType][residue] += normalizedCount\n",
    "                    \n",
    "                    else:\n",
    "                        avgDict[histoneType][residue] = normalizedCount\n",
    "                        \n",
    "                else:\n",
    "                    avgDict[histoneType] = {residue : normalizedCount}\n",
    "                    \n",
    "            elif(sourceFields[-2] != 'other' and sourceFields[-3] != 'other'):#MAKE ENTRIES HAVE THE SAME NUMBER OF ELEMENTS!!!\n",
    "                histoneType = sourceFields[3]\n",
    "                normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                \n",
    "                if(histoneType in avgDict):\n",
    "                    \n",
    "                    if(residue in avgDict[histoneType]):\n",
    "                        avgDict[histoneType][residue] += normalizedCount\n",
    "                    \n",
    "                    else:\n",
    "                        avgDict[histoneType][residue] = normalizedCount\n",
    "                        \n",
    "                else:\n",
    "                    avgDict[histoneType] = {residue : normalizedCount}\n",
    "    \n",
    "    return avgDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_contacts(interfaceDictionary):\n",
    "    \n",
    "    sumDict = {}\n",
    "\n",
    "    for pair in interfaceDictionary:\n",
    "        if(pair != 'uniprotPair'):\n",
    "\n",
    "            randomResidue = list(interfaceDictionary[pair].keys())[0]\n",
    "\n",
    "            targetFields = interfaceDictionary[pair][randomResidue][0].split('@')[0].split('#')\n",
    "            sourceFields = interfaceDictionary[pair][randomResidue][0].split('@')[-1].split('#')\n",
    "            \n",
    "            pdbList = []\n",
    "            for residue in interfaceDictionary[pair]:\n",
    "                pdbIDs = interfaceDictionary[pair][residue][2].split('$')\n",
    "                \n",
    "                for pdb in pdbIDs:\n",
    "                    \n",
    "                    if(pdb not in pdbList):\n",
    "                        pdbList.append(pdb)\n",
    "            \n",
    "            \n",
    "            interfaceFlag = 0\n",
    "            \n",
    "            if(targetFields[-2] != 'other' and targetFields[-3] != 'other'):\n",
    "                histoneType = targetFields[3]\n",
    "                    \n",
    "                newPair = histoneType + '@'\n",
    "                \n",
    "                if(sourceFields[-2] != 'other' and sourceFields[-3] != 'other'):\n",
    "                    histoneType2 = sourceFields[3]\n",
    "                                 \n",
    "                    newPair += histoneType2\n",
    "                    \n",
    "                else:   \n",
    "                    for field in sourceFields:\n",
    "                        newPair += field + '#'\n",
    "                        interfaceFlag = 1\n",
    "                        \n",
    "                totalCount = 0\n",
    "\n",
    "                for residue in interfaceDictionary[pair]:\n",
    "                    normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                    totalCount += normalizedCount\n",
    "                \n",
    "                if(newPair in sumDict):\n",
    "                    sumDict[newPair][0] += totalCount\n",
    "                \n",
    "                else:\n",
    "                    sumDict[newPair] = [totalCount, pdbList]\n",
    "\n",
    "            elif(sourceFields[-2] != 'other' and sourceFields[-3] != 'other'):\n",
    "                histoneType = sourceFields[3]\n",
    "                \n",
    "                newPair = histoneType + '@'\n",
    "                    \n",
    "                for field in targetFields:\n",
    "                    newPair += field + '#'                 \n",
    "                    \n",
    "                totalCount = 0\n",
    "\n",
    "                for residue in interfaceDictionary[pair]:\n",
    "                    normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                    totalCount += normalizedCount\n",
    "\n",
    "                if(newPair in sumDict):\n",
    "                    sumDict[newPair][0] += totalCount\n",
    "                \n",
    "                else:\n",
    "                    sumDict[newPair] = [totalCount, pdbList]\n",
    "                    \n",
    "            else:\n",
    "                newPair = ''\n",
    "                \n",
    "                for field in targetFields:\n",
    "                    newPair += field + '#'\n",
    "                    \n",
    "                newPair += '@'\n",
    "                \n",
    "                for field in sourceFields:\n",
    "                    newPair += field + '#'    \n",
    "                   \n",
    "                totalCount = 0\n",
    "\n",
    "                for residue in interfaceDictionary[pair]:\n",
    "                    normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                    totalCount += normalizedCount\n",
    "\n",
    "                if(newPair in sumDict):\n",
    "                    sumDict[newPair][0] += totalCount\n",
    "                \n",
    "                else:\n",
    "                    sumDict[newPair] = [totalCount, pdbList]\n",
    "            \n",
    "            #####Have to account for the case when an interface between two non-histone chains is already in the dictionary, but is stored in a reverse order!!!!\n",
    "\n",
    "    return sumDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    chainDictionary = {}\n",
    "    chainDictionary['chain'] = {}\n",
    "    \n",
    "    get_chain_dictionaries(CHAIN_FILE, chainDictionary)\n",
    "    \n",
    "    interfaceFiles = []\n",
    "    get_files(PDB_LIST, interfaceFiles, 'interface')\n",
    "    \n",
    "    interfaceDictionary = {}\n",
    "    interfaceDictionary['uniprotPair'] = {}\n",
    "    \n",
    "    residue_count(interfaceFiles, chainDictionary, interfaceDictionary)\n",
    "    \n",
    "    normalize_count(interfaceDictionary)\n",
    "    #for pair in interfaceDictionary:\n",
    "    #    print(pair + ': ' + str(interfaceDictionary[pair]))\n",
    "    #    print('\\n')\n",
    "    \n",
    "    avgDict = average_histones(interfaceDictionary)\n",
    "    #print(avgDict)    \n",
    "    \n",
    "    sumDict = sum_contacts(interfaceDictionary)\n",
    "    print('target' + '\\t' + 'source' + '\\t' + 'contacts')\n",
    "    pdbList = '1zla,1aoi,1eqz,1f66,1hio,1hq3,1id3,1kx3,1kx4,1kx5,1m18,1m19,1m1a,1p34,1p3a,1p3b,1p3f,1p3g,1p3i,1p3k,1p3l,1p3m,1p3o,1p3p,1s32,1tzy,1u35,1zbb,2aro,2cv5,2f8n,2fj7,2hio,2nqb,2nzd,2pyo,3a6n,3afa,3an2,3av1,3av2,3ayw,3aze,3azf,3azg,3azh,3azi,3azj,3azk,3azl,3azm,3azn,3b6f,3b6g,3c1b,3c1c,3kuy,3kwq,3kxb,3lel,3lja,3lz0,3lz1,3mgp,3mgq,3mgr,3mgs,3mnn,3mvd,3o62,3reh,3rei,3rej,3rek,3rel,3tu4,3ut9,3uta,3utb,3w96,3w97,3w98,3w99,3wa9,3waa,3wkj,3wtp,3x1s,3x1t,3x1u,3x1v,4j8u,4j8v,4j8w,4j8x,4jjn,4kgc,4kud,4ld9,4qlc,4r8p,4wu8,4wu9,4x23,4xuj,4xzq,4ym5,4ym6,4ys3,4z5t,4z66,4zux,5av5,5av6,5av8,5av9,5avb,5avc,5ay8,5b0y,5b0z,5b1l,5b1m,5b24,5b2i,5b2j,5b31,5b32,5b33,5b40,5cp6,5cpi,5cpj,5cpk,5dnm,5dnn,5e5a,5f99,5gse,5gsu,5gt0,5gt3,5gtc,5gxq,5hq2,5jrg,5kgf,5mlu,5nl0,5o9g,5omx,5ong,5onw,5oxv,5oy7,5x0x,5x0y,5x7x,5xf3,5xf4,5xf5,5xf6,5xm0,5xm1,6buz,6c0w,6esf,6esg,6esh,6esi,6etx,6fml,6fq5,6fq6,6fq8'.split(',')\n",
    "\n",
    "    for pair in sumDict:\n",
    "        chains = pair.split('@')\n",
    "        target = chains[0]\n",
    "        source = chains[1]\n",
    "        \n",
    "        contacts = sumDict[pair][0]\n",
    "        pdbIDs = ''\n",
    "        \n",
    "        for pdb in sumDict[pair][1]:\n",
    "            pdbIDs += pdb + '#'\n",
    "\n",
    "        targetFields = target.split('#')\n",
    "        sourceFields = source.split('#')\n",
    "        \n",
    "        smallList = pdbIDs.split('#')\n",
    "        \n",
    "        intersectionFlag = 0\n",
    "        \n",
    "        for sPDB in smallList:\n",
    "            \n",
    "            if(sPDB in pdbList):\n",
    "                intersectionFlag = 1\n",
    "                break\n",
    "        \n",
    "        if(len(targetFields) > 1 and intersectionFlag):\n",
    "            print(source + '\\t' + target + '\\t' + pdbIDs + '\\t' + 'nucleosome')\n",
    "            \n",
    "        elif(len(sourceFields) > 1 and intersectionFlag):\n",
    "            print(target + '\\t' + source + '\\t' + pdbIDs + '\\t' + 'nucleosome')\n",
    "            \n",
    "        elif(intersectionFlag):\n",
    "            print(target + '\\t' + source + '\\t' + pdbIDs + '\\t' + 'nucleosome')\n",
    "            \n",
    "        else:\n",
    "            print(target + '\\t' + source + '\\t' + pdbIDs + '\\t' + 'histone')\n",
    "            \n",
    "        #print(target + '\\t' + source + '\\t' + str(contacts))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1zla\tnucleosome\tyes bp\n",
      "target\tsource\tcontacts\n",
      "h3\th4\t1zla#\tnucleosome\n",
      "h3\th2a\t1zla#\tnucleosome\n",
      "h3\th3\t1zla#\tnucleosome\n",
      "h4\th2a\t1zla#\tnucleosome\n",
      "h4\th2b\t1zla#\tnucleosome\n",
      "h2a\th2b\t1zla#\tnucleosome\n",
      "h2a\th2a\t1zla#\tnucleosome\n",
      "h2a\tK#Q9DUM3#NA#other#1#1#\t1zla#\tnucleosome\n",
      "h2b\tK#Q9DUM3#NA#other#1#1#\t1zla#\tnucleosome\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
