{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES:\n",
    "#To get a list of PDB that contains histones from 'text.csv':\n",
    "#cut -f1 text.tsv | uniq | awk '{print tolower($0)}' | sort\n",
    "\n",
    "#text.tsv should be sorted by pdb and then uniprot name\n",
    "#it MUST have 'NA' in uniprot and name blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python 3\n",
    "import re\n",
    "\n",
    "PATH = \"../data/Interfaces/\"\n",
    "#PATH = \"/net/pan1/interactomes/pipeline/Interactome/Workflow/Interfaces/\"\n",
    "CHAIN_FILE = \"text.tsv\"\n",
    "PDB_LIST = \"pdbList.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#fils is a string with path to the file to be checked\n",
    "\n",
    "#RESULTS:\n",
    "#Returns 1 or 0 depending on file existence \n",
    "\n",
    "\n",
    "def file_check(file):\n",
    "    \n",
    "    try:\n",
    "        open(file, \"r\")\n",
    "        return 1\n",
    "    \n",
    "    except IOError:\n",
    "        print(\"Error: \" + file + \" does not appear to exist.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#name is a string with the name of chain\n",
    "#typeCount is a 2-element list with the first one being an empty string and the second - 0 (iteger)\n",
    "\n",
    "#RESULTS:\n",
    "#Updates the typeCount array: the first element = general histone type(s); the second element = (should be) number of histones in chain\n",
    "\n",
    "def is_histone(name, typeCount):\n",
    "\n",
    "    if(not re.search(r'chaperone|ase|binding|p53 peptide|non-histone|jmjc|rna|synth', name, re.I)):\n",
    "        if(re.search(r'histone.*h?\\d|h?\\d.*histone|h?\\d.*histone-like|histone-like.*h?\\d|histone macro.*h?\\d|h?\\d.*histone macro|h?\\d.*\\speptide|\\speptide.*h?\\d|h3k4me0|h3(1-9)k4me3|$h\\d^|archaeal histone|histone peptide', name, re.I)):\n",
    "            typeCount[1] = 1 #adds the number of histones in chain  (should be changed to actual number of histones in chain!!!)\n",
    "\n",
    "            if(re.search(r'h2a', name, re.I)):\n",
    "                typeCount[0] += 'h2a|'\n",
    "                \n",
    "            elif(re.search(r'h2b', name, re.I)):\n",
    "                typeCount[0] += 'h2b|'\n",
    "                    \n",
    "            elif(re.search(r'h3', name, re.I)):\n",
    "                typeCount[0] += 'h3|'\n",
    "                    \n",
    "            elif(re.search(r'h4', name, re.I)):\n",
    "                typeCount[0] += 'h4|'\n",
    "                    \n",
    "            elif(re.search(r'h1', name, re.I)):\n",
    "                typeCount[0] += 'h1|'  \n",
    "                    \n",
    "            elif(re.search(r'h5', name, re.I)):\n",
    "                typeCount[0] += 'h5|'\n",
    "                    \n",
    "            else:\n",
    "                typeCount[0] += 'some histone|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdbList is a text file with a header and one column PDB\n",
    "#files is a list\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#A list of absolute paths to either mapping files or interface files as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_files(pdbList, files, parameter):\n",
    "    \n",
    "    with open(pdbList, 'r') as pfh:\n",
    "        pfh.readline()\n",
    "        \n",
    "        if(parameter == 'mapping'):\n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2] \n",
    "                files.append(PATH + folder + '/' + line + '_chain_protein_mapping.tab')\n",
    "                \n",
    "        elif(parameter == 'interface'): \n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2]\n",
    "                files.append(PATH + folder + '/' + line + '_atomic_contacts_5.0A.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdb is a string with pdb id\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#An absolute paths to either mapping file or interface file as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_file(pdb, parameter):\n",
    "    \n",
    "    if(parameter == 'mapping'):\n",
    "        folder = pdb[1] + pdb[2] \n",
    "        file = (PATH + folder + '/' + pdb + '_chain_protein_mapping.tab')\n",
    "        return file  \n",
    "        \n",
    "    elif(parameter == 'interface'): \n",
    "        folder = pdb[1] + pdb[2]\n",
    "        file = (PATH + folder + '/' + pdb + '_atomic_contacts_5.0A.tab')\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#cFile is tab-separated file with a header and 4 columns: pdb, chain, uniprot, name\n",
    "#dictionary is nested with the innermost dict being dictionary['pdb'] = {}\n",
    "\n",
    "#RESULTS:\n",
    "#The format of the end-product dictionary is: {pdb : {AlexChain: myChain|UNIPROT|name|type|nucleosome(bool)|bindingPartner(bool)}}\n",
    "#Example: {1alq : {'G': 'E|P02302|Histone H3.3C|H3|1|0'}}\n",
    "\n",
    "\n",
    "def get_chain_dictionaries(cFile, dictionary): \n",
    "    \n",
    "    with open(cFile, 'r') as cfh:\n",
    "        cfh.readline()\n",
    "        \n",
    "        histoneCount = {} #is used to count number of histones in a structure!!!!!!!\n",
    "        \n",
    "        tempDict = {}\n",
    "        tempDict['pdb'] = {}\n",
    "            \n",
    "        mappingFiles = [] \n",
    "        get_files(PDB_LIST, mappingFiles, 'mapping')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for file in mappingFiles:\n",
    "\n",
    "            try: #adds a pdb entry to the dict only if mapping file exists\n",
    "\n",
    "                with open(file, 'r') as mfh:\n",
    "                    mfh.readline() #skips header\n",
    "                    pdb = file.split('/')[-1].split('_', 1)[0]\n",
    "\n",
    "                    for mLine in mfh:\n",
    "                        chainPair = mLine.split('\\t', 2)\n",
    "                        alexChain = chainPair[0]\n",
    "                        myChain = chainPair[1]\n",
    "                        \n",
    "                        if(pdb in tempDict):\n",
    "                            tempDict[pdb][alexChain] = myChain\n",
    "                        else:\n",
    "                            tempDict[pdb] = {alexChain : myChain}\n",
    "\n",
    "            except IOError:\n",
    "                pass\n",
    "                #print(\"Error: \" + mappingFile + \" does not appear to exist.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for cLine in cfh:           \n",
    "            fields = cLine.strip().split('\\t')\n",
    "            \n",
    "            pdb = fields[0]\n",
    "    \n",
    "            if(pdb in tempDict): #continues only if a mapping file exists\n",
    "                chain = fields[1]\n",
    "                uniprot = fields[2]\n",
    "                name = fields[3]\n",
    "                #function = fields[4] !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "                #organism = fields[5] !!!!!!!!!!!!!!!!!!!!!!!!!!!!\n",
    "\n",
    "                histoneTypeAndCount = ['', 0]\n",
    "\n",
    "                is_histone(name, histoneTypeAndCount) #checks whether the name looks like a histone!!!!!!!!!\n",
    "\n",
    "                tempType = histoneTypeAndCount[0]\n",
    "                tempCount = histoneTypeAndCount[1]\n",
    "                \n",
    "                \n",
    "                #######################\n",
    "                if(tempCount): #if the chain is a [part of a] histone\n",
    "                    \n",
    "                    if(pdb in histoneCount):\n",
    "                        \n",
    "                        if(tempType not in histoneCount[pdb]):\n",
    "                            histoneCount[pdb].append(tempType) #!!!!!!\n",
    "\n",
    "                    else:\n",
    "                        histoneCount[pdb] = [tempType]\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                try: #adds a chain entry to the dict only if there exists a corresponding chain in the mapping file\n",
    "                    alexChain = list(tempDict[pdb].keys())[list(tempDict[pdb].values()).index(chain)]\n",
    "\n",
    "                    if(pdb in dictionary):\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + tempType #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + 'other|' #!!!!\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + tempType} #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + 'other|'} #!!!!\n",
    "                        \n",
    "                except ValueError:\n",
    "                    #print(\"Error: \" + ValueError + \", in \" + pdb)               \n",
    "                    pass\n",
    "\n",
    "                    \n",
    "                    \n",
    "        for structure in list(dictionary):\n",
    "            \n",
    "            if(structure in histoneCount):\n",
    "                uniqueHistoneNum = len(histoneCount[structure])\n",
    "                partnerFlag = 0\n",
    "            \n",
    "                if(uniqueHistoneNum > 3): #checks if pdb has at least a half of a nucleosome!!!!!!!\n",
    "\n",
    "                    for chain in dictionary[structure]:\n",
    "                        chainFields = dictionary[structure][chain].split('|')\n",
    "\n",
    "                        chainType = chainFields[3]##\n",
    "                        #chainName = chainFields[1] + '\\t' + chainFields[2]\n",
    "\n",
    "                        dictionary[structure][chain] += 'nucleosome:1|' #!!!!!!\n",
    "\n",
    "                        if(partnerFlag == 0 and chainType == 'other'):\n",
    "                            partnerFlag = 1\n",
    "\n",
    "\n",
    "                    if(partnerFlag == 0):\n",
    "\n",
    "                        for chain in dictionary[structure]:\n",
    "                            dictionary[structure][chain] += 'bp:0|'\n",
    "                            print(dictionary[structure][chain])\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        for chain in dictionary[structure]:\n",
    "                            dictionary[structure][chain] += 'bp:1|'\n",
    "                            print(dictionary[structure][chain])\n",
    "\n",
    "                else: #!!!!!!\n",
    "\n",
    "                    for chain in dictionary[structure]: #!!!!!\n",
    "                        chainFields = dictionary[structure][chain].split('|')\n",
    "\n",
    "                        chainType = chainFields[3]\n",
    "                        #chainName = chainFields[1] + '\\t' + chainFields[2]\n",
    "\n",
    "                        dictionary[structure][chain] += 'nucleosome:0|' #!!!!!! \n",
    "\n",
    "                        if(partnerFlag == 0 and chainType == 'other'):\n",
    "                            partnerFlag = 1\n",
    "\n",
    "                    if(partnerFlag == 0):\n",
    "\n",
    "                        for chain in dictionary[structure]:\n",
    "                            dictionary[structure][chain] += 'bp:0|'\n",
    "                            print(dictionary[structure][chain])\n",
    "                    else:\n",
    "\n",
    "                        for chain in dictionary[structure]:\n",
    "                            dictionary[structure][chain] += 'bp:1|'\n",
    "                            print(dictionary[structure][chain])\n",
    "            \n",
    "            else:\n",
    "                del dictionary[structure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#interfaceFiles is a list of strings containing names of interface files\n",
    "#chainDictionary is a dictionary produced by 'get_chain_dictionaries'\n",
    "#interfaceDictonary is a nested dictionary with the innermost dict being interfaceDictionary['uniprotPair'] = {}, where the values are lists of the next form [chain pair data, residue number, pdb IDs] \n",
    "#Example: 'P84233@P62799': {'44': ['A|P84233|Histone H3.2|h3|1@B|P62799|Histone H4|h4|1$E|P84233|Histone H3.2|h3|1@F|P62799|Histone H4|h4|1', 17, '1zla$q5cl']\n",
    "#note that data fields of a chain is separated by |, @ separates chain from binding partner chain, $ separates chain pairs and pdb structures\n",
    "\n",
    "\n",
    "def residue_count(interfaceFiles, chainDictionary, interfaceDictionary):\n",
    "    \n",
    "    for file in interfaceFiles:\n",
    "        pdb = file.split('/')[-1].split('_', 1)[0] \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            with open (file, 'r') as ifh:\n",
    "                ifh.readline() #skips header\n",
    "\n",
    "                for line in ifh:\n",
    "                    lineFields = line.split('\\t', 6) #gets only the first 8 columns !!!\n",
    "\n",
    "                    chain1 = lineFields[0].split('_', 1)[0] # the split part treats biological assembly chains as separate chains ???\n",
    "                    chain2 = lineFields[4].split('_', 1)[0]\n",
    "\n",
    "                    residue1 = lineFields[2]\n",
    "                    residue2 = lineFields[5]\n",
    "\n",
    "                    uniprot1 = chainDictionary[pdb][chain1].split('|', 2)[1]\n",
    "                    uniprot2 = chainDictionary[pdb][chain2].split('|', 2)[1]\n",
    "\n",
    "                    uniprotPair1 = uniprot1 + '@' + uniprot2\n",
    "                    uniprotPair2 = uniprot2 + '@' + uniprot1\n",
    "\n",
    "                    chainPair1 = chainDictionary[pdb][chain1] + '@' + chainDictionary[pdb][chain2]\n",
    "                    chainPair2 = chainDictionary[pdb][chain2] + '@' + chainDictionary[pdb][chain1]\n",
    "\n",
    "                    if(uniprotPair1 in interfaceDictionary):\n",
    "\n",
    "                        if(residue1 in interfaceDictionary[uniprotPair1]):\n",
    "                            interfaceDictionary[uniprotPair1][residue1][1] += 1  \n",
    "\n",
    "                            if(chainPair1 not in interfaceDictionary[uniprotPair1][residue1][0]):\n",
    "                                interfaceDictionary[uniprotPair1][residue1][0] += '$' + chainPair1                       \n",
    "                                \n",
    "                                if(pdb not in interfaceDictionary[uniprotPair1][residue1][2]):\n",
    "                                    interfaceDictionary[uniprotPair1][residue1][2] += '$' + pdb\n",
    "                                   \n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair1][residue1] = [chainPair1, 1, pdb]    #format of the innermost dict        \n",
    "\n",
    "                    elif(uniprotPair2 in interfaceDictionary):\n",
    "\n",
    "                        if(residue2 in interfaceDictionary[uniprotPair2]):\n",
    "                            interfaceDictionary[uniprotPair2][residue2][1] += 1\n",
    "\n",
    "                            if(chainPair2 not in interfaceDictionary[uniprotPair2][residue2][0]):\n",
    "                                interfaceDictionary[uniprotPair2][residue2][0] += '$' + chainPair2                        \n",
    "\n",
    "                                if(pdb not in interfaceDictionary[uniprotPair2][residue2][2]):\n",
    "                                    interfaceDictionary[uniprotPair2][residue2][2] += '$' + pdb\n",
    "                                    \n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair2][residue2] = [chainPair2, 1, pdb]\n",
    "\n",
    "                    else:\n",
    "                         interfaceDictionary[uniprotPair1] = {residue1 : [chainPair1, 1, pdb]}  \n",
    "                            \n",
    "        except IOError:\n",
    "            #print(\"Error: \" + interfaceFile + \" does not appear to exist.\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_count(interfaceDictionary):\n",
    "    \n",
    "    for pair in interfaceDictionary:\n",
    "        \n",
    "        for residue in interfaceDictionary[pair]:\n",
    "            pdbCount = len(interfaceDictionary[pair][residue][2].split('$'))\n",
    "            interfaceDictionary[pair][residue].append(interfaceDictionary[pair][residue][1] / pdbCount) #[3] is normalized by uniprot pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_histones(interfaceDictionary):\n",
    "    \n",
    "    avgDict = {}\n",
    "    avgDict['type'] = {}\n",
    "\n",
    "    for pair in interfaceDictionary:\n",
    "        \n",
    "        for residue in interfaceDictionary[pair]:                           \n",
    "            targetFields = interfaceDictionary[pair][residue][0].split('@')[0].split('|')\n",
    "            sourceFields = interfaceDictionary[pair][residue][0].split('@')[1].split('|') \n",
    "            \n",
    "            if(targetFields[3] != 'other'): #MAKE ENTRIES HAVE THE SAME NUMBER OF ELEMENTS!!!\n",
    "                histoneType = targetFields[3]\n",
    "                normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                \n",
    "                if(histoneType in avgDict):\n",
    "                    \n",
    "                    if(residue in avgDict[histoneType]):\n",
    "                        avgDict[histoneType][residue] += normalizedCount\n",
    "                    \n",
    "                    else:\n",
    "                        avgDict[histoneType][residue] = normalizedCount\n",
    "                        \n",
    "                else:\n",
    "                    avgDict[histoneType] = {residue : normalizedCount}\n",
    "                    \n",
    "            elif(sourceFields[3] != 'other'):#MAKE ENTRIES HAVE THE SAME NUMBER OF ELEMENTS!!!\n",
    "                histoneType = sourceFields[3]\n",
    "                normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                \n",
    "                if(histoneType in avgDict):\n",
    "                    \n",
    "                    if(residue in avgDict[histoneType]):\n",
    "                        avgDict[histoneType][residue] += normalizedCount\n",
    "                    \n",
    "                    else:\n",
    "                        avgDict[histoneType][residue] = normalizedCount\n",
    "                        \n",
    "                else:\n",
    "                    avgDict[histoneType] = {residue : normalizedCount}\n",
    "    \n",
    "    return avgDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_contacts(interfaceDictionary):\n",
    "    \n",
    "    sumDict = {}\n",
    "\n",
    "    for pair in interfaceDictionary:\n",
    "        \n",
    "        if(pair != 'uniprotPair'):\n",
    "            \n",
    "            targetFields = []\n",
    "            sourceFields = []\n",
    "            \n",
    "            nucleosomeFlag = 0\n",
    "            for residue in interfaceDictionary[pair]:\n",
    "                pairs = interfaceDictionary[pair][residue][0].split('$')\n",
    "                \n",
    "                for instance in pairs:\n",
    "                    targetFields = instance.split('@')[0].split('|')\n",
    "                    sourceFields = instance.split('@')[1].split('|') \n",
    "                    \n",
    "\n",
    "                    if(targetFields[4].split(':')[1] == '1' or sourceFields[4].split(':')[1] == '1'):\n",
    "                        nucleosomeFlag = 1\n",
    "                        break\n",
    "                \n",
    "                if(nucleosomeFlag):\n",
    "                    break\n",
    "            \n",
    "            #randomResidue = list(interfaceDictionary[pair].keys())[0]\n",
    "            #randomPair = interfaceDictionary[pair][randomResidue][0].split('$')[0]\n",
    "            \n",
    "            #targetFields = randomPair.split('@')[0].split('|')\n",
    "            #sourceFields = randomPair.split('@')[1].split('|') \n",
    "            \n",
    "            pdbList = []\n",
    "            \n",
    "            for residue in interfaceDictionary[pair]:\n",
    "                pdbIDs = interfaceDictionary[pair][residue][2].split('$')\n",
    "                \n",
    "                for pdb in pdbIDs:\n",
    "                    \n",
    "                    if(pdb not in pdbList):\n",
    "                        pdbList.append(pdb)\n",
    "            \n",
    "            if(targetFields[3] != 'other'):\n",
    "                histoneType = targetFields[3]\n",
    "                    \n",
    "                newPair = histoneType + '@'\n",
    "                \n",
    "                if(sourceFields[3] != 'other'):\n",
    "                    histoneType2 = sourceFields[3]\n",
    "                                 \n",
    "                    newPair += histoneType2\n",
    "                    \n",
    "                else:   \n",
    "                    \n",
    "                    for field in sourceFields:\n",
    "                        if(field == sourceFields[len(sourceFields) - 1]):\n",
    "                            newPair += field\n",
    "                        else:\n",
    "                            newPair += field + '|'\n",
    "                        \n",
    "                totalCount = 0\n",
    "\n",
    "                for residue in interfaceDictionary[pair]:\n",
    "                    normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                    totalCount += normalizedCount\n",
    "                \n",
    "                if(newPair in sumDict):\n",
    "                    sumDict[newPair][0] += totalCount\n",
    "                \n",
    "                else:\n",
    "                    sumDict[newPair] = [totalCount, pdbList]\n",
    "\n",
    "            elif(sourceFields[3] != 'other'):\n",
    "                histoneType = sourceFields[3]\n",
    "                \n",
    "                newPair = histoneType + '@'\n",
    "                    \n",
    "                for field in targetFields:\n",
    "                    if(field == targetFields[len(targetFields) - 1]):\n",
    "                        newPair += field\n",
    "                    else:\n",
    "                        newPair += field + '|'               \n",
    "                    \n",
    "                totalCount = 0\n",
    "\n",
    "                for residue in interfaceDictionary[pair]:\n",
    "                    normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                    totalCount += normalizedCount\n",
    "\n",
    "                if(newPair in sumDict):\n",
    "                    sumDict[newPair][0] += totalCount\n",
    "                \n",
    "                else:\n",
    "                    sumDict[newPair] = [totalCount, pdbList]\n",
    "                    \n",
    "            else:\n",
    "                newPair = ''\n",
    "                \n",
    "                for field in targetFields:\n",
    "                    if(field == targetFields[len(targetFields) - 1]):\n",
    "                        newPair += field\n",
    "                    else:\n",
    "                        newPair += field + '|'\n",
    "                    \n",
    "                newPair += '@'\n",
    "                \n",
    "                for field in sourceFields:\n",
    "                    if(field == sourceFields[len(sourceFields) - 1]):\n",
    "                        newPair += field\n",
    "                    else:\n",
    "                        newPair += field + '|'  \n",
    "                   \n",
    "                totalCount = 0\n",
    "\n",
    "                for residue in interfaceDictionary[pair]:\n",
    "                    normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                    totalCount += normalizedCount\n",
    "\n",
    "                if(newPair in sumDict):\n",
    "                    sumDict[newPair][0] += totalCount\n",
    "                \n",
    "                else:\n",
    "                    sumDict[newPair] = [totalCount, pdbList]\n",
    "            \n",
    "            #####Have to account for the case when an interface between two non-histone chains is already in the dictionary, but is stored in a reverse order!!!!\n",
    "\n",
    "    return sumDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    chainDictionary = {}\n",
    "    chainDictionary['chain'] = {}\n",
    "    \n",
    "    get_chain_dictionaries(CHAIN_FILE, chainDictionary)\n",
    "\n",
    "    interfaceFiles = []\n",
    "    get_files(PDB_LIST, interfaceFiles, 'interface')\n",
    "    \n",
    "    interfaceDictionary = {}\n",
    "    interfaceDictionary['uniprotPair'] = {}\n",
    "    \n",
    "    residue_count(interfaceFiles, chainDictionary, interfaceDictionary)\n",
    "\n",
    "    normalize_count(interfaceDictionary)\n",
    "    #for pair in interfaceDictionary:\n",
    "    #    print(pair + ': ' + str(interfaceDictionary[pair]))\n",
    "    #    print('\\n')\n",
    "    \n",
    "    avgDict = average_histones(interfaceDictionary)\n",
    "    \n",
    "    sumDict = sum_contacts(interfaceDictionary)\n",
    "    for pair in sumDict:\n",
    "        chains = pair.split('@')\n",
    "        target = chains[0]\n",
    "        source = chains[1]\n",
    "        \n",
    "        pdbIDs = ''\n",
    "        \n",
    "        for pdb in sumDict[pair][1]:\n",
    "            \n",
    "            if(pdb == sumDict[pair][1][len(sumDict[pair][1]) - 1]):\n",
    "                pdbIDs += pdb\n",
    "                \n",
    "            else:\n",
    "                pdbIDs += pdb + '|'\n",
    "\n",
    "        targetFields = target.split('|')\n",
    "        sourceFields = source.split('|')      \n",
    "        \n",
    "        if(len(targetFields) > 1 and targetFields[4].split(':')[1] == '1'):\n",
    "            print(source + '\\t' + target + '\\t' + pdbIDs + '\\t' + 'nucleosome')\n",
    "            \n",
    "        elif(len(sourceFields) > 1 and sourceFields[4].split(':')[1] == '1'):\n",
    "            print(target + '\\t' + source + '\\t' + pdbIDs + '\\t' + 'nucleosome')\n",
    "            \n",
    "        elif(len(sourceFields) == 1 and len(targetFields) == 1):\n",
    "            print(target + '\\t' + source + '\\t' + pdbIDs + '\\t' + 'NA')\n",
    "            \n",
    "        else:\n",
    "            print(target + '\\t' + source + '\\t' + pdbIDs + '\\t' + 'histone')\n",
    "        \n",
    "        #contacts = sumDict[pair][0]    \n",
    "        #print(target + '\\t' + source + '\\t' + str(contacts))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C|P06897|Histone H2A type 1|h2a|nucleosome:1|bp:1|\n",
      "G|P06897|Histone H2A type 1|h2a|nucleosome:1|bp:1|\n",
      "D|P02281|Histone H2B 1.1|h2b|nucleosome:1|bp:1|\n",
      "H|P02281|Histone H2B 1.1|h2b|nucleosome:1|bp:1|\n",
      "A|P84233|Histone H3.2|h3|nucleosome:1|bp:1|\n",
      "E|P84233|Histone H3.2|h3|nucleosome:1|bp:1|\n",
      "B|P62799|Histone H4|h4|nucleosome:1|bp:1|\n",
      "F|P62799|Histone H4|h4|nucleosome:1|bp:1|\n",
      "K|Q9DUM3|NA|other|nucleosome:1|bp:1|\n",
      "h3\th4\t1zla\tNA\n",
      "h3\th2a\t1zla\tNA\n",
      "h3\th3\t1zla\tNA\n",
      "h4\th2a\t1zla\tNA\n",
      "h4\th2b\t1zla\tNA\n",
      "h2a\th2b\t1zla\tNA\n",
      "h2a\th2a\t1zla\tNA\n",
      "h2a\tK|Q9DUM3|NA|other|nucleosome:1|bp:1|\t1zla\tnucleosome\n",
      "h2b\tK|Q9DUM3|NA|other|nucleosome:1|bp:1|\t1zla\tnucleosome\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
