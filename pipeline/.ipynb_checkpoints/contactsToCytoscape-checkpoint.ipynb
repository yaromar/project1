{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES:\n",
    "#To get a list of PDB that contains histones from 'text.csv':\n",
    "#cut -f1 text.tsv | uniq | awk '{print tolower($0)}' | sort\n",
    "\n",
    "#text.tsv should be sorted by pdb and then uniprot name\n",
    "#it MUST have 'NA' in uniprot and name blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python 3\n",
    "import re\n",
    "\n",
    "PATH = \"../data/Interfaces/\"\n",
    "#PATH = \"/net/pan1/interactomes/pipeline/Interactome/Workflow/Interfaces/\"\n",
    "CHAIN_FILE = \"text.tsv\"\n",
    "PDB_LIST = \"pdbList.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#fils is a string with path to the file to be checked\n",
    "\n",
    "#RESULTS:\n",
    "#Returns 1 or 0 depending on file existence \n",
    "\n",
    "\n",
    "def file_check(file):\n",
    "    \n",
    "    try:\n",
    "        open(file, \"r\")\n",
    "        return 1\n",
    "    \n",
    "    except IOError:\n",
    "        print(\"Error: \" + file + \" does not appear to exist.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#name is a string with the name of chain\n",
    "#typeCount is a 2-element list with the first one being an empty string and the second - 0 (iteger)\n",
    "\n",
    "#RESULTS:\n",
    "#Updates the typeCount array: the first element = general histone type(s); the second element = (should be) number of histones in chain\n",
    "\n",
    "def is_histone(name, typeCount):\n",
    "\n",
    "    if(not re.search(r'chaperone|ase|binding|p53 peptide|non-histone|jmjc|rna|synth', name, re.I)):\n",
    "        if(re.search(r'histone.*h?\\d|h?\\d.*histone|h?\\d.*histone-like|histone-like.*h?\\d|histone macro.*h?\\d|h?\\d.*histone macro|h?\\d.*\\speptide|\\speptide.*h?\\d|h3k4me0|h3(1-9)k4me3|$h\\d^|archaeal histone|histone peptide', name, re.I)):\n",
    "            typeCount[1] = 1 #adds the number of histones in chain  (should be changed to actual number of histones in chain)\n",
    "\n",
    "            if(re.search(r'h2a', name, re.I)):\n",
    "                typeCount[0] += 'h2a#'\n",
    "                \n",
    "            elif(re.search(r'h2b', name, re.I)):\n",
    "                typeCount[0] += 'h2b#'\n",
    "                    \n",
    "            elif(re.search(r'h3', name, re.I)):\n",
    "                typeCount[0] += 'h3#'\n",
    "                    \n",
    "            elif(re.search(r'h4', name, re.I)):\n",
    "                typeCount[0] += 'h4#'\n",
    "                    \n",
    "            elif(re.search(r'h1', name, re.I)):\n",
    "                typeCount[0] += 'h1#'  \n",
    "                    \n",
    "            elif(re.search(r'h5', name, re.I)):\n",
    "                typeCount[0] += 'h5#'\n",
    "                    \n",
    "            else:\n",
    "                typeCount[0] += 'some histone#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdbList is a text file with a header and one column PDB\n",
    "#files is a list\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#A list of absolute paths to either mapping files or interface files as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_files(pdbList, files, parameter):\n",
    "    \n",
    "    with open(pdbList, 'r') as pfh:\n",
    "        pfh.readline()\n",
    "        \n",
    "        if(parameter == 'mapping'):\n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2] \n",
    "                files.append(PATH + folder + '/' + line + '_chain_protein_mapping.tab')\n",
    "                \n",
    "        elif(parameter == 'interface'): \n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2]\n",
    "                files.append(PATH + folder + '/' + line + '_atomic_contacts_5.0A.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdb is a string with pdb id\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#An absolute paths to either mapping file or interface file as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_file(pdb, parameter):\n",
    "    \n",
    "    if(parameter == 'mapping'):\n",
    "        folder = pdb[1] + pdb[2] \n",
    "        file = (PATH + folder + '/' + pdb + '_chain_protein_mapping.tab')\n",
    "        return file  \n",
    "        \n",
    "    elif(parameter == 'interface'): \n",
    "        folder = pdb[1] + pdb[2]\n",
    "        file = (PATH + folder + '/' + pdb + '_atomic_contacts_5.0A.tab')\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#cFile is tab-separated file with a header and 4 columns: pdb, chain, uniprot, name\n",
    "#dictionary is nested with the innermost dict being dictionary['pdb'] = {}\n",
    "\n",
    "#RESULTS:\n",
    "#The format of the end-product dictionary is: {pdb : {AlexChain: myChain#UNIPROT#name#type#nucleosome(bool)}}\n",
    "#Example: {1alq : {'G': 'E#P02302#Histone H3.3C#H3#1'}}\n",
    "\n",
    "\n",
    "def get_chain_dictionaries(cFile, dictionary): \n",
    "    \n",
    "    with open(cFile, 'r') as cfh:\n",
    "        cfh.readline()\n",
    "        \n",
    "        histoneCount = {} #is used to count number of histones in a structure!!!!!!!\n",
    "        \n",
    "        tempDict = {}\n",
    "        tempDict['pdb'] = {}\n",
    "            \n",
    "        mappingFiles = [] \n",
    "        get_files(PDB_LIST, mappingFiles, 'mapping')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for file in mappingFiles:\n",
    "            try: #adds a pdb entry to the dict only if mapping file exists\n",
    "\n",
    "                with open(file, 'r') as mfh:\n",
    "                    mfh.readline() #skips header\n",
    "                    pdb = file.split('/')[-1].split('_', 1)[0]\n",
    "\n",
    "                    for mLine in mfh:\n",
    "                        chainPair = mLine.split('\\t', 2)\n",
    "                        alexChain = chainPair[0]\n",
    "                        myChain = chainPair[1]\n",
    "                        \n",
    "                        if(pdb in tempDict):\n",
    "                            tempDict[pdb][alexChain] = myChain\n",
    "                        else:\n",
    "                            tempDict[pdb] = {alexChain : myChain}\n",
    "\n",
    "            except IOError:\n",
    "                pass\n",
    "                #print(\"Error: \" + mappingFile + \" does not appear to exist.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for cLine in cfh:           \n",
    "            fields = cLine.strip().split('\\t')\n",
    "            \n",
    "            pdb = fields[0]\n",
    "    \n",
    "            if(pdb in tempDict): #continues only if a mapping file exists\n",
    "                chain = fields[1]\n",
    "                uniprot = fields[2]\n",
    "                name = fields[3]\n",
    "\n",
    "\n",
    "                histoneTypeAndCount = ['', 0]\n",
    "\n",
    "                is_histone(name, histoneTypeAndCount) #checks whether the name looks like a histone!!!!!!!!!\n",
    "\n",
    "                tempType = histoneTypeAndCount[0]\n",
    "                tempCount = histoneTypeAndCount[1]\n",
    "\n",
    "                if(pdb in histoneCount):\n",
    "                    histoneCount[pdb] += tempCount #!!!!!!\n",
    "                else:\n",
    "                    histoneCount[pdb] = tempCount\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                try: #adds a chain entry to the dict only if there exists a corresponding chain in the mapping file\n",
    "                    alexChain = list(tempDict[pdb].keys())[list(tempDict[pdb].values()).index(chain)]\n",
    "\n",
    "                    if(pdb in dictionary):\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + tempType #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + 'other#' #!!!!\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + tempType} #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + 'other#'} #!!!!\n",
    "                        \n",
    "                except ValueError:\n",
    "                    #print(\"Error: \" + ValueError + \", in \" + pdb)               \n",
    "                    pass\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        for structure in histoneCount:\n",
    "\n",
    "            if(histoneCount[structure] > 3): #checks if pdb has at least a half of nucleosome!!!!!!!\n",
    "\n",
    "                for chain in dictionary[structure]: #!!!!!!\n",
    "                    dictionary[structure][chain] = dictionary[structure][chain] + '1' #!!!!!!\n",
    "\n",
    "            else: #!!!!!!\n",
    "\n",
    "                for chain in dictionary[structure]: #!!!!!\n",
    "                    dictionary[structure][chain] = dictionary[structure][chain] + '0' #!!!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#interfaceFiles is a list of strings containing names of interface files\n",
    "#chainDictionary is a dictionary produced by 'get_chain_dictionaries'\n",
    "#interfaceDictonary is a nested dictionary with the innermost dict being interfaceDictionary['uniprotPair'] = {}, where the values are lists of the next form [chain pair data, residue number, pdb IDs] \n",
    "#Example: 'P84233@P62799': {'44': ['A#P84233#Histone H3.2#h3#1@B#P62799#Histone H4#h4#1$E#P84233#Histone H3.2#h3#1@F#P62799#Histone H4#h4#1', 17, '1zla$q5cl']\n",
    "#note that data fields of a chain is separated by #, @ separates chains binding partner chains, $ separates chain pairs and pdb structures\n",
    "\n",
    "\n",
    "def residue_count(interfaceFiles, chainDictionary, interfaceDictionary):\n",
    "    for file in interfaceFiles:\n",
    "        pdb = file.split('/')[-1].split('_', 1)[0] \n",
    "        \n",
    "        try:\n",
    "            with open (file, 'r') as ifh:\n",
    "                ifh.readline() #skips header\n",
    "\n",
    "                for line in ifh:\n",
    "                    lineFields = line.split('\\t', 6) #gets only the first 8 columns !!!\n",
    "\n",
    "                    chain1 = lineFields[0].split('_', 1)[0] # the split part treats biological assembly chains as separate chains ???\n",
    "                    chain2 = lineFields[4].split('_', 1)[0]\n",
    "\n",
    "                    residue1 = lineFields[2]\n",
    "                    residue2 = lineFields[5]\n",
    "\n",
    "                    uniprot1 = chainDictionary[pdb][chain1].split('#', 2)[1]\n",
    "                    uniprot2 = chainDictionary[pdb][chain2].split('#', 2)[1]\n",
    "\n",
    "                    uniprotPair1 = uniprot1 + '@' + uniprot2\n",
    "                    uniprotPair2 = uniprot2 + '@' + uniprot1\n",
    "\n",
    "                    chainPair1 = chainDictionary[pdb][chain1] + '@' + chainDictionary[pdb][chain2]\n",
    "                    chainPair2 = chainDictionary[pdb][chain2] + '@' + chainDictionary[pdb][chain1]\n",
    "\n",
    "                    if(uniprotPair1 in interfaceDictionary):\n",
    "\n",
    "                        if(residue1 in interfaceDictionary[uniprotPair1]):\n",
    "                            interfaceDictionary[uniprotPair1][residue1][1] += 1  \n",
    "\n",
    "                            if(chainPair1 not in interfaceDictionary[uniprotPair1][residue1][0]):\n",
    "                                interfaceDictionary[uniprotPair1][residue1][0] += '$' + chainPair1                       \n",
    "                                \n",
    "                                if(pdb not in interfaceDictionary[uniprotPair1][residue1][2]):\n",
    "                                    interfaceDictionary[uniprotPair1][residue1][2] += '$' + pdb\n",
    "                                   \n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair1][residue1] = [chainPair1, 1, pdb]    #format of the innermost dict        \n",
    "\n",
    "                    elif(uniprotPair2 in interfaceDictionary):\n",
    "\n",
    "                        if(residue2 in interfaceDictionary[uniprotPair2]):\n",
    "                            interfaceDictionary[uniprotPair2][residue2][1] += 1\n",
    "\n",
    "                            if(chainPair2 not in interfaceDictionary[uniprotPair2][residue2][0]):\n",
    "                                interfaceDictionary[uniprotPair2][residue2][0] += '$' + chainPair2                        \n",
    "\n",
    "                                if(pdb not in interfaceDictionary[uniprotPair2][residue2][2]):\n",
    "                                    interfaceDictionary[uniprotPair2][residue2][2] += '$' + pdb\n",
    "                                    \n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair2][residue2] = [chainPair2, 1, pdb]\n",
    "\n",
    "                    else:\n",
    "                         interfaceDictionary[uniprotPair1] = {residue1 : [chainPair1, 1, pdb]}  \n",
    "                            \n",
    "        except IOError:\n",
    "            #print(\"Error: \" + interfaceFile + \" does not appear to exist.\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_count(interfaceDictionary):\n",
    "    \n",
    "    for pair in interfaceDictionary:\n",
    "        \n",
    "        for residue in interfaceDictionary[pair]:\n",
    "            pdbCount = len(interfaceDictionary[pair][residue][2].split('$'))\n",
    "            interfaceDictionary[pair][residue].append(interfaceDictionary[pair][residue][1] / pdbCount) #[3] is normalized by uniprot pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_histones(interfaceDictionary):\n",
    "    \n",
    "    avgDict = {}\n",
    "    avgDict['type'] = {}\n",
    "\n",
    "    for pair in interfaceDictionary:\n",
    "        \n",
    "        for residue in interfaceDictionary[pair]:                           \n",
    "            targetFields = interfaceDictionary[pair][residue][0].split('@')[0].split('#')\n",
    "            sourceFields = interfaceDictionary[pair][residue][0].split('@')[-1].split('#')\n",
    "            \n",
    "            if(targetFields[-2] != 'other'):\n",
    "                histoneType = targetFields[3]\n",
    "                normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                \n",
    "                if(histoneType in avgDict):\n",
    "                    \n",
    "                    if(residue in avgDict[histoneType]):\n",
    "                        avgDict[histoneType][residue] += normalizedCount\n",
    "                    \n",
    "                    else:\n",
    "                        avgDict[histoneType][residue] = normalizedCount\n",
    "                        \n",
    "                else:\n",
    "                    avgDict[histoneType] = {residue : normalizedCount}\n",
    "                    \n",
    "            elif(sourceFields[-2] != 'other'):\n",
    "                histoneType = sourceFields[3]\n",
    "                normalizedCount = interfaceDictionary[pair][residue][3]\n",
    "                \n",
    "                if(histoneType in avgDict):\n",
    "                    \n",
    "                    if(residue in avgDict[histoneType]):\n",
    "                        avgDict[histoneType][residue] += normalizedCount\n",
    "                    \n",
    "                    else:\n",
    "                        avgDict[histoneType][residue] = normalizedCount\n",
    "                        \n",
    "                else:\n",
    "                    avgDict[histoneType] = {residue : normalizedCount}\n",
    "    \n",
    "    return avgDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_contacts(interfaceDictionary):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    chainDictionary = {}\n",
    "    chainDictionary['chain'] = {}\n",
    "    \n",
    "    get_chain_dictionaries(CHAIN_FILE, chainDictionary)\n",
    "    \n",
    "    interfaceFiles = []\n",
    "    get_files(PDB_LIST, interfaceFiles, 'interface')\n",
    "    \n",
    "    interfaceDictionary = {}\n",
    "    interfaceDictionary['uniprotPair'] = {}\n",
    "    \n",
    "    residue_count(interfaceFiles, chainDictionary, interfaceDictionary)\n",
    "    \n",
    "    normalize_count(interfaceDictionary)\n",
    "    \n",
    "    #for pair in interfaceDictionary:\n",
    "     #   print(pair + ': ' + str(interfaceDictionary[pair]))\n",
    "      #  print('\\n')\n",
    "    \n",
    "    #avgDict = average_histones(interfaceDictionary)\n",
    "    \n",
    "    print(avgDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': {}, 'h3': {'44': 17.0, '47': 52.0, '48': 32.0, '50': 60.0, '51': 128.0, '54': 130.0, '55': 125.0, '57': 33.0, '58': 66.0, '59': 44.0, '60': 10.0, '61': 147.0, '62': 37.0, '63': 5.0, '66': 17.0, '67': 25.0, '69': 51.0, '70': 80.0, '71': 18.0, '73': 98.0, '74': 55.0, '75': 16.0, '78': 100.0, '79': 40.0, '81': 25.0, '82': 47.0, '83': 113.0, '84': 70.0, '85': 86.0, '87': 40.0, '88': 54.0, '90': 25.0, '91': 59.0, '92': 41.0, '94': 55.0, '95': 33.0, '96': 40.0, '97': 21.0, '98': 8.0, '99': 121.0, '100': 42.0, '101': 55.0, '103': 6.0, '104': 124.0, '105': 37.0, '108': 60.0, '117': 39.0, '118': 108.0, '119': 117.0, '120': 33.0, '121': 87.0, '124': 21.0, '125': 24.0, '128': 23.0, '134': 5.0, '72': 4.0, '76': 7.0, '131': 11.0, '42': 2.0, '52': 7.0, '56': 12.0, '109': 28.0, '112': 11.0, 'T': 62.0, 'K': 9.0, 'Q': 68.0, 'S': 7.0, 'A': 4.0, 'E': 40.0, 'L': 23.0, 'V': 7.0, 'I': 14.0, 'R': 6.0, 'N': 6.0, '129': 19.0, '132': 2.0, '106': 18.0, '110': 23.0, '111': 2.0, '113': 71.0, '114': 19.0, '116': 5.0, '122': 11.0, '123': 11.0, '126': 29.0, '127': 6.0, '130': 53.0}, 'h4': {'64': 1.0, '40': 9.0, '42': 3.0, '44': 23.0, '94': 4.0, '95': 6.0, '96': 47.0, '97': 29.0, '98': 163.0, '99': 26.0, '100': 7.0, 'Y': 144.0, 'T': 44.0, 'G': 61.0, 'R': 19.0, 'L': 26.0, 'F': 7.0, 'K': 29.0, 'V': 1.0, '68': 24.0, '71': 30.0, '72': 69.0, '74': 6.0, '75': 216.0, '76': 19.0, '77': 23.0, '88': 118.0, '91': 7.0, '92': 96.0, '101': 5.0, '102': 34.0, '78': 1.0}, 'h2a': {'17': 42.0, '19': 5.0, '20': 115.0, '21': 88.0, '22': 9.0, '23': 8.0, '24': 72.0, '25': 90.0, '26': 70.0, '29': 97.0, '30': 21.0, '32': 25.0, '33': 32.0, '34': 26.0, '38': 60.0, '39': 152.0, '40': 55.0, '41': 55.0, '42': 122.0, '43': 30.0, '44': 25.0, '45': 13.0, '46': 33.0, '47': 67.0, '49': 69.0, '50': 269.0, '51': 41.0, '53': 21.0, '54': 34.0, '55': 58.0, '56': 26.0, '57': 172.0, '58': 44.0, '59': 43.0, '60': 28.0, '61': 66.0, '62': 24.0, '63': 86.0, '64': 102.0, '65': 3.0, '67': 32.0, '68': 27.0, '70': 2.0, '76': 53.0, '77': 89.0, '78': 130.0, '79': 32.0, '80': 58.0, '83': 35.0, '92': 143.0, '93': 20.0, '95': 16.0, '96': 65.0, '97': 24.0, '100': 7.0, '102': 19.0, '103': 10.0, '104': 3.0, '36': 3.0, '37': 8.0, 'K': 4.0, 'N': 11.0, 'G': 7.0, '35': 1.0, '90': 11.0}, 'h2b': {'44': 2.0, '47': 46.0, '48': 19.0, '49': 5.0, '105': 10.0, '106': 23.0, '109': 43.0, '113': 44.0, '116': 9.0}}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
