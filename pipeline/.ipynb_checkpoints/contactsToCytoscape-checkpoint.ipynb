{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#NOTES:\n",
    "#To get a list of PDB that contains histones from 'text.csv':\n",
    "#cut -f1 text.tsv | uniq | awk '{print tolower($0)}' | sort\n",
    "\n",
    "#text.tsv should be sorted by pdb and then uniprot name\n",
    "#it MUST have 'NA' in uniprot and name blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python 3\n",
    "import re\n",
    "\n",
    "PATH = \"/net/pan1/interactomes/pipeline/Interactome/Workflow/Interfaces/\"\n",
    "CHAIN_FILE = \"text.tsv\"\n",
    "PDB_LIST = \"pdbList.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#fils is a string with path to the file to be checked\n",
    "\n",
    "#RESULTS:\n",
    "#Returns 1 or 0 depending on file existence \n",
    "\n",
    "\n",
    "def file_check(file):\n",
    "    \n",
    "    try:\n",
    "        open(file, \"r\")\n",
    "        return 1\n",
    "    \n",
    "    except IOError:\n",
    "        print(\"Error: \" + file + \" does not appear to exist.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#name is a string with the name of chain\n",
    "#typeCount is a 2-element list with the first one being an empty string and the second - 0 (iteger)\n",
    "\n",
    "#RESULTS:\n",
    "#Updates the typeCount array: the first element = general histone type(s); the second element = (should be) number of histones in chain\n",
    "\n",
    "def is_histone(name, typeCount):\n",
    "\n",
    "    if(not re.search(r'chaperone|ase|binding|p53 peptide|non-histone|jmjc|rna|synth', name, re.I)):\n",
    "        if(re.search(r'histone.*h?\\d|h?\\d.*histone|h?\\d.*histone-like|histone-like.*h?\\d|histone macro.*h?\\d|h?\\d.*histone macro|h?\\d.*\\speptide|\\speptide.*h?\\d|h3k4me0|h3(1-9)k4me3|$h\\d^|archaeal histone|histone peptide', name, re.I)):\n",
    "            typeCount[1] = 1 #adds the number of histones in chain  (should be changed to actual number of histones in chain)\n",
    "\n",
    "            if(re.search(r'h2a', name, re.I)):\n",
    "                typeCount[0] += 'h2a#'\n",
    "                \n",
    "            elif(re.search(r'h2b', name, re.I)):\n",
    "                typeCount[0] += 'h2b#'\n",
    "                    \n",
    "            elif(re.search(r'h3', name, re.I)):\n",
    "                typeCount[0] += 'h3#'\n",
    "                    \n",
    "            elif(re.search(r'h4', name, re.I)):\n",
    "                typeCount[0] += 'h4#'\n",
    "                    \n",
    "            elif(re.search(r'h1', name, re.I)):\n",
    "                typeCount[0] += 'h1#'  \n",
    "                    \n",
    "            elif(re.search(r'h5', name, re.I)):\n",
    "                typeCount[0] += 'h5#'\n",
    "                    \n",
    "            else:\n",
    "                typeCount[0] += 'some histone'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdbList is a text file with a header and one column PDB\n",
    "#files is a list\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#A list of absolute paths to either mapping files or interface files as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_files(pdbList, files, parameter):\n",
    "    \n",
    "    with open(pdbList, 'r') as pfh:\n",
    "        pfh.readline()\n",
    "        \n",
    "        if(parameter == 'mapping'):\n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2] \n",
    "                files.append(PATH + folder + '/' + line + '_chain_protein_mapping.tab')\n",
    "                \n",
    "        elif(parameter == 'interface'): \n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2]\n",
    "                files.append(PATH + folder + '/' + line + '_atomic_contacts_5.0A.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdb is a string with pdb id\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#An absolute paths to either mapping file or interface file as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_file(pdb, parameter):\n",
    "    \n",
    "    if(parameter == 'mapping'):\n",
    "        folder = pdb[1] + pdb[2] \n",
    "        file = (PATH + folder + '/' + pdb + '_chain_protein_mapping.tab')\n",
    "        return file  \n",
    "        \n",
    "    elif(parameter == 'interface'): \n",
    "        folder = pdb[1] + pdb[2]\n",
    "        file = (PATH + folder + '/' + pdb + '_atomic_contacts_5.0A.tab')\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#cFile is tab-separated file with a header and 4 columns: pdb, chain, uniprot, name\n",
    "#dictionary is nested with the innermost dict being dictionary['pdb'] = {}\n",
    "\n",
    "#RESULTS:\n",
    "#The format of the end-product dictionary is: {pdb : {AlexChain: myChain#UNIPROT#name#type#nucleosome(bool)}}\n",
    "#Example: {1alq : {'G': 'E#P02302#Histone H3.3C#H3#1'}}\n",
    "\n",
    "\n",
    "def get_chain_dictionaries(cFile, dictionary): \n",
    "    \n",
    "    with open(cFile, 'r') as cfh:\n",
    "        cfh.readline()\n",
    "        \n",
    "        histoneCount = {} #is used to count number of histones in a structure!!!!!!!\n",
    "        \n",
    "        tempDict = {}\n",
    "        tempDict['pdb'] = {}\n",
    "            \n",
    "        mappingFiles = [] \n",
    "        get_files(PDB_LIST, mappingFiles, 'mapping')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for file in mappingFiles:\n",
    "            try: #adds a pdb entry to the dict only if mapping file exists\n",
    "\n",
    "                with open(file, 'r') as mfh:\n",
    "                    mfh.readline() #skips header\n",
    "                    pdb = file.split('/')[-1].split('_', 1)[0]\n",
    "\n",
    "                    for mLine in mfh:\n",
    "                        chainPair = mLine.split('\\t', 2)\n",
    "                        alexChain = chainPair[0]\n",
    "                        myChain = chainPair[1]\n",
    "                        \n",
    "                        if(pdb in tempDict):\n",
    "                            tempDict[pdb][alexChain] = myChain\n",
    "                        else:\n",
    "                            tempDict[pdb] = {alexChain : myChain}\n",
    "\n",
    "            except IOError:\n",
    "                pass\n",
    "                #print(\"Error: \" + mappingFile + \" does not appear to exist.\")\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        for cLine in cfh:           \n",
    "            fields = cLine.strip().split('\\t')\n",
    "            \n",
    "            pdb = fields[0]\n",
    "    \n",
    "            if(pdb in tempDict): #continues only if a mapping file exists\n",
    "                chain = fields[1]\n",
    "                uniprot = fields[2]\n",
    "                name = fields[3]\n",
    "\n",
    "\n",
    "                histoneTypeAndCount = ['', 0]\n",
    "\n",
    "                is_histone(name, histoneTypeAndCount) #checks whether the name looks like a histone!!!!!!!!!\n",
    "\n",
    "                tempType = histoneTypeAndCount[0]\n",
    "                tempCount = histoneTypeAndCount[1]\n",
    "\n",
    "                if(pdb in histoneCount):\n",
    "                    histoneCount[pdb] += tempCount #!!!!!!\n",
    "                else:\n",
    "                    histoneCount[pdb] = tempCount\n",
    "\n",
    "                        \n",
    "                        \n",
    "                        \n",
    "                try: #adds a chain entry to the dict only if there exists a corresponding chain in the mapping file\n",
    "                    alexChain = list(tempDict[pdb].keys())[list(tempDict[pdb].values()).index(chain)]\n",
    "\n",
    "                    if(pdb in dictionary):\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + tempType #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + 'other#' #!!!!\n",
    "\n",
    "                    else:\n",
    "\n",
    "                        if(tempCount): #checks if chain is a histone!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + tempType} #!!!!\n",
    "\n",
    "                        else: #!!!!\n",
    "                            dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '#' + uniprot + '#' + name + '#' + 'other#'} #!!!!\n",
    "                        \n",
    "                except ValueError:\n",
    "                    #print(\"Error: \" + ValueError + \", in \" + pdb)               \n",
    "                    pass\n",
    "\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "        for structure in histoneCount:\n",
    "\n",
    "            if(histoneCount[structure] > 3): #checks if pdb has at least a half of nucleosome!!!!!!!\n",
    "\n",
    "                for chain in dictionary[structure]: #!!!!!!\n",
    "                    dictionary[structure][chain] = dictionary[structure][chain] + '1' #!!!!!!\n",
    "\n",
    "            else: #!!!!!!\n",
    "\n",
    "                for chain in dictionary[structure]: #!!!!!\n",
    "                    dictionary[structure][chain] = dictionary[structure][chain] + '0' #!!!!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#interfaceFiles is a list of strings containing names of interface files\n",
    "#chainDictionary is a dictionary produced by 'get_chain_dictionaries'\n",
    "#interfaceDictonary is a nested dictionary with the innermost dict being interfaceDictionary['uniprotPair'] = {}\n",
    "#Example: 'P84233@P62799': {'44': ['$A#P84233#Histone H3.2#h3#1@B#P62799#Histone H4#h4#1$E#P84233#Histone H3.2#h3#1@F#P62799#Histone H4#h4#1', 17]\n",
    "#note that data of a chain is separated by #!!!!!!!!\n",
    "\n",
    "\n",
    "def residue_frequency(interfaceFiles, chainDictionary, interfaceDictionary):\n",
    "    for file in interfaceFiles:\n",
    "        pdb = file.split('/')[-1].split('_', 1)[0] \n",
    "        \n",
    "        try:\n",
    "            with open (file, 'r') as ifh:\n",
    "                ifh.readline() #skips header\n",
    "\n",
    "                for line in ifh:\n",
    "                    lineFields = line.split('\\t', 6) #gets only the first 8 columns !!!\n",
    "\n",
    "                    chain1 = lineFields[0].split('_', 1)[0] # split treats biologica assembly chains as separate chains ???\n",
    "                    chain2 = lineFields[4].split('_', 1)[0]\n",
    "\n",
    "                    residue1 = lineFields[2]\n",
    "                    residue2 = lineFields[5]\n",
    "\n",
    "                    uniprot1 = chainDictionary[pdb][chain1].split('#', 2)[1]\n",
    "                    uniprot2 = chainDictionary[pdb][chain2].split('#', 2)[1]\n",
    "\n",
    "                    uniprotPair1 = uniprot1 + '@' + uniprot2\n",
    "                    uniprotPair2 = uniprot2 + '@' + uniprot1\n",
    "\n",
    "                    chainPair1 = chainDictionary[pdb][chain1] + '@' + chainDictionary[pdb][chain2]\n",
    "                    chainPair2 = chainDictionary[pdb][chain2] + '@' + chainDictionary[pdb][chain1]\n",
    "\n",
    "                    if(uniprotPair1 in interfaceDictionary):\n",
    "\n",
    "                        if(residue1 in interfaceDictionary[uniprotPair1]):\n",
    "                            interfaceDictionary[uniprotPair1][residue1][1] += 1  \n",
    "\n",
    "                            if(chainPair1 not in interfaceDictionary[uniprotPair1][residue1][0]):\n",
    "                                interfaceDictionary[uniprotPair1][residue1][0] += '$' + chainPair1                       \n",
    "\n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair1][residue1] = [chainPair1, 1]           \n",
    "\n",
    "                    elif(uniprotPair2 in interfaceDictionary):\n",
    "\n",
    "                        if(residue2 in interfaceDictionary[uniprotPair2]):\n",
    "                            interfaceDictionary[uniprotPair2][residue2][1] += 1\n",
    "\n",
    "                            if(chainPair2 not in interfaceDictionary[uniprotPair2][residue2][0]):\n",
    "                                interfaceDictionary[uniprotPair2][residue2][0] += '$' + chainPair2                        \n",
    "\n",
    "                        else:\n",
    "                            interfaceDictionary[uniprotPair2][residue2] = [chainPair2, 1]\n",
    "\n",
    "                    else:\n",
    "                         interfaceDictionary[uniprotPair1] = {residue1 : [chainPair1, 1]}  \n",
    "        except IOError:\n",
    "            #print(\"Error: \" + interfaceFile + \" does not appear to exist.\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    print('hmmm')\n",
    "    chainDictionary = {}\n",
    "    chainDictionary['chain'] = {}\n",
    "    \n",
    "    get_chain_dictionaries(CHAIN_FILE, chainDictionary)\n",
    "    \n",
    "    interfaceFiles = []\n",
    "    get_files(PDB_LIST, interfaceFiles, 'interface')\n",
    "    \n",
    "    interfaceDictionary = {}\n",
    "    interfaceDictionary['uniprotPair'] = {}\n",
    "    \n",
    "    residue_frequency(interfaceFiles, chainDictionary, interfaceDictionary)\n",
    "    \n",
    "    print('wth')\n",
    "    print(interfaceDictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hmmm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
