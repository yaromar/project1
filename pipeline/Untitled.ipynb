{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTES:\n",
    "#To get a list of PDB that contains histones from 'text.csv':\n",
    "#cut -f1 text.tsv | uniq | awk '{print tolower($0)}' | sort\n",
    "\n",
    "#text.tsv should be sorted by pdb and then uniprot name\n",
    "#it MUST have 'NA' in uniprot and name blanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python 3\n",
    "import re\n",
    "\n",
    "PATH = \"/net/pan1/interactomes/pipeline/Interactome/Workflow/Interfaces/\"\n",
    "CHAIN_FILE = \"text.tsv\"\n",
    "PDB_LIST = \"pdbList.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#fils is a string with path to the file to be checked\n",
    "\n",
    "#RESULTS:\n",
    "#Returns 1 or 0 depending on file existence \n",
    "\n",
    "\n",
    "def file_check(file):\n",
    "    \n",
    "    try:\n",
    "        open(file, \"r\")\n",
    "        return 1\n",
    "    \n",
    "    except IOError:\n",
    "        print(\"Error: \" + file + \" does not appear to exist.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#name is a string with the name of chain\n",
    "#typeCount is a 2-element list with the first one being an empty string and the second - 0 (iteger)\n",
    "\n",
    "#RESULTS:\n",
    "#Updates the typeCount array: the first element = general histone type(s); the second element = number of histones in chain\n",
    "\n",
    "def is_histone(name, typeCount):\n",
    "    if(not len(re.findall(r'chaperone|ase|binding|p53 peptide|non-histone|jmjc|rna|synth', name, re.I))):\n",
    "        matchHistone = re.findall(r'histone.*(h)?\\d|(h)?\\d.*histone|(h)?\\d.*histone-like|histone-like.*(h)?\\d|histone macro.*(h)?\\d|(h)?\\d.*histone macro|(h)?\\d.*\\speptide|\\speptide.*(h)?\\d|h3k4me0|h3(1-9)k4me3|$h\\d^|archaeal histone|histone peptide', name, re.I)\n",
    "        typeCount[1] = len(matchHistone) #adds the number of histones in chain  \n",
    "        \n",
    "        if(typeCount[1]): #if the name appears to be histone\n",
    "            matchType = re.findall(r'h\\d', name, re.I)\n",
    "            \n",
    "            if(not len(matchType)):\n",
    "                typeCount[0] = 'some histone'\n",
    "                \n",
    "            else:\n",
    "                for match in matchType:\n",
    "                    typeCount[0] += match+'#'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdbList is a text file with a header and one column PDB\n",
    "#files is a list\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#A list of absolute paths to either mapping files or interface files as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_files(pdbList, files, parameter):\n",
    "    \n",
    "    with open(pdbList, 'r') as pfh:\n",
    "        pfh.readline()\n",
    "        \n",
    "        if(parameter == 'mapping'):\n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2] \n",
    "                files.append(PATH + folder + '/' + line + '_chain_protein_mapping.tab')\n",
    "                \n",
    "        elif(parameter == 'interface'): \n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2]\n",
    "                files.append(PATH + folder + '/' + line + '_atomic_contacts_5.0A.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#cFile is tab-separated file with a header and 4 columns: pdb, chain, uniprot, name\n",
    "#dictionary is nested with the innermost dict being dictionary['pdb'] = {}\n",
    "\n",
    "#RESULTS:\n",
    "#The format of the end-product dictionary is: {pdb : {AlexChain: myChain#UNIPROT#name#type#nucleosome(bool)}}\n",
    "#Example: {1alq : {'G': 'E#P02302#Histone H3.3C#H3#1'}}\n",
    "\n",
    "\n",
    "def get_chain_dictionaries(cFile, dictionary):  \n",
    "    with open(cFile, 'r') as cfh:\n",
    "        cfh.readline() #skips header\n",
    "        \n",
    "        for cLine in cfh:\n",
    "            fields = cLine.strip().split('\\t')\n",
    "            pdb = fields[0]\n",
    "            folder = pdb[1] + pdb[2] #folder name in \". . . Interfaces/\"        \n",
    "            \n",
    "            tempDict = {}\n",
    "            \n",
    "            mappingFile = PATH + folder + '/' + pdb + '_chain_protein_mapping.tab'\n",
    "            \n",
    "            try: #adds a pdb entry to the dict only if mapping file exists\n",
    "                \n",
    "                with open(mappingFile, 'r') as mfh:\n",
    "                    mfh.readline() #skips header\n",
    "                    \n",
    "                    for mLine in mfh:\n",
    "                        chainPair = mLine.split('\\t', 2)\n",
    "                        alexChain = chainPair[0]\n",
    "                        myChain = chainPair[1]\n",
    "\n",
    "                        tempDict[alexChain] = myChain\n",
    "                \n",
    "                dictionary[pdb] = {}\n",
    "                pdbTemp = pdb\n",
    "                histoneCount = 0 #is used to count number of histones in a structure!!!!!!!\n",
    "                \n",
    "                while(pdbTemp == pdb): #parses lines that have the same pdb (must be sorted)\n",
    "                    chain = fields[1]\n",
    "                    uniprot = fields[2]\n",
    "                    name = fields[3]\n",
    "\n",
    "                    if(not(uniprot == 'NA' and name == 'NA')): #prevents from wasting time on nucleotide chains\n",
    "                        histoneTypeAndCount = ['', 0]\n",
    "                        \n",
    "                        is_histone(name, histoneTypeAndCount) #checks whether the name looks like a histone!!!!!!!!!\n",
    "                        \n",
    "                        tempType = histoneTypeAndCount[0]\n",
    "                        tempCount = histoneTypeAndCount[1]\n",
    "\n",
    "                        histoneCount += tempCount #!!!!!!\n",
    "\n",
    "                        try: #adds a chain entry to the dict only if there exists a corresponding chain in the mapping file\n",
    "                            alexChain = list(tempDict.keys())[list(tempDict.values()).index(chain)]\n",
    "                            \n",
    "                            if(tempCount): #!!!!\n",
    "                                dictionary[pdb][alexChain] = str(tempDict[alexChain]) + '#' + uniprot + '#' + name + '#' + tempType #!!!!\n",
    "                                \n",
    "                            else: #!!!!\n",
    "                                dictionary[pdb][alexChain] = str(tempDict[alexChain]) + '#' + uniprot + '#' + name + '#' + 'other#' #!!!!\n",
    "                                \n",
    "                        except ValueError:\n",
    "                \n",
    "                            pass\n",
    "                            #print(\"Error: \" + ValueError + \", in \" + pdb)\n",
    "                            \n",
    "                    cLine = cfh.readline()\n",
    "                    \n",
    "                    fields = cLine.strip().split('\\t')\n",
    "                    pdbTemp = fields[0]\n",
    "                \n",
    "                if(histoneCount > 3): #checks if pdb has at least a half of nucleosome!!!!!!!\n",
    "                    \n",
    "                    for chain in dictionary[pdb]: #!!!!!!\n",
    "                        dictionary[pdb][chain] = dictionary[pdb][chain] + '1' #!!!!!!\n",
    "                    print(pdb)       \n",
    "                else: #!!!!!!\n",
    "                    \n",
    "                    for chain in dictionary[pdb]: #!!!!!\n",
    "                        dictionary[pdb][chain] = dictionary[pdb][chain] + '0' #!!!!!! [\n",
    " \n",
    "            except IOError:    \n",
    "                #print(\"Error: \" + mappingFile + \" does not appear to exist.\")\n",
    "\n",
    "                pdbTemp = pdb\n",
    "                \n",
    "                while(pdbTemp == pdb): #skips lines with pdb that doesn't have a corresponding mapping file\n",
    "                    cLine = cfh.readline()\n",
    "                    fields = cLine.strip().split('\\t', 1)\n",
    "                    pdbTemp = fields[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "\n",
    "    chainDictionary = {}\n",
    "    chainDictionary['pdb'] = {}\n",
    "    \n",
    "    get_chain_dictionaries(CHAIN_FILE, chainDictionary)\n",
    "    \n",
    "    \n",
    "    interfaceFiles = []\n",
    "    get_files(PDB_LIST, interfaceFiles, 'interface')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1aoi\n",
      "1eqz\n",
      "1f66\n",
      "1hq3\n",
      "1id3\n",
      "1kx3\n",
      "1kx4\n",
      "1kx5\n",
      "1m18\n",
      "1m19\n",
      "1m1a\n",
      "1p34\n",
      "1p3a\n",
      "1p3b\n",
      "1p3f\n",
      "1p3g\n",
      "1p3i\n",
      "1p3k\n",
      "1p3l\n",
      "1p3m\n",
      "1p3o\n",
      "1p3p\n",
      "1s32\n",
      "1tzy\n",
      "1u35\n",
      "1zbb\n",
      "1zla\n",
      "2aro\n",
      "2cv5\n",
      "2f8n\n",
      "2fj7\n",
      "2hio\n",
      "2nqb\n",
      "2nzd\n",
      "2pyo\n",
      "2x4y\n",
      "2xql\n",
      "2yfw\n",
      "3a6n\n",
      "3afa\n",
      "3an2\n",
      "3av1\n",
      "3av2\n",
      "3ayw\n",
      "3aze\n",
      "3azf\n",
      "3azg\n",
      "3azh\n",
      "3azi\n",
      "3azj\n",
      "3azk\n",
      "3azl\n",
      "3azm\n",
      "3azn\n",
      "3b6f\n",
      "3b6g\n",
      "3c1b\n",
      "3c1c\n",
      "3kuy\n",
      "3kwq\n",
      "3kxb\n",
      "3lel\n",
      "3lja\n",
      "3lz0\n",
      "3lz1\n",
      "3mgp\n",
      "3mgq\n",
      "3mgr\n",
      "3mgs\n",
      "3mnn\n",
      "3mvd\n",
      "3o62\n",
      "3qo2\n",
      "3reh\n",
      "3rei\n",
      "3rej\n",
      "3rek\n",
      "3rel\n",
      "3szm\n",
      "3tu4\n",
      "3u5o\n",
      "3u5p\n",
      "3ut9\n",
      "3uta\n",
      "3utb\n",
      "3w96\n",
      "3w97\n",
      "3w98\n",
      "3w99\n",
      "3wa9\n",
      "3waa\n",
      "3wkj\n",
      "3wtp\n",
      "3x1s\n",
      "3x1t\n",
      "3x1u\n",
      "3x1v\n",
      "4h9s\n",
      "4j8u\n",
      "4j8v\n",
      "4j8w\n",
      "4j8x\n",
      "4jjn\n",
      "4kgc\n",
      "4kud\n",
      "4ld9\n",
      "4nft\n",
      "4psx\n",
      "4qlc\n",
      "4quf\n",
      "4r8p\n",
      "4u9w\n",
      "4wnn\n",
      "4wu8\n",
      "4wu9\n",
      "4x23\n",
      "4xuj\n",
      "4xzq\n",
      "4ym5\n",
      "4ym6\n",
      "4ys3\n",
      "4z2m\n",
      "4z5t\n",
      "4z66\n",
      "4zux\n",
      "5av5\n",
      "5av6\n",
      "5av8\n",
      "5av9\n",
      "5avb\n",
      "5avc\n",
      "5ay8\n",
      "5b0y\n",
      "5b0z\n",
      "5b1l\n",
      "5b1m\n",
      "5b24\n",
      "5b2i\n",
      "5b2j\n",
      "5b31\n",
      "5b32\n",
      "5b33\n",
      "5b40\n",
      "5bnv\n",
      "5c3i\n",
      "5cp6\n",
      "5cpi\n",
      "5cpj\n",
      "5cpk\n",
      "5dnm\n",
      "5dnn\n",
      "5e5a\n",
      "5f99\n",
      "5fug\n",
      "5g2e\n",
      "5gse\n",
      "5gsu\n",
      "5gt0\n",
      "5gt3\n",
      "5gtc\n",
      "5gxq\n",
      "5hjd\n",
      "5hq2\n",
      "5jrg\n",
      "5jxt\n",
      "5kgf\n",
      "5mlu\n",
      "5nl0\n",
      "5o9g\n",
      "5omx\n",
      "5ong\n",
      "5onw\n",
      "5oxv\n",
      "5oy7\n",
      "5x0x\n",
      "5x0y\n",
      "5x7x\n",
      "5xf3\n",
      "5xf4\n",
      "5xf5\n",
      "5xf6\n",
      "5xm0\n",
      "5xm1\n",
      "6buz\n",
      "6c0w\n",
      "6esf\n",
      "6esg\n",
      "6esh\n",
      "6esi\n",
      "6etx\n",
      "6fml\n",
      "6fq5\n",
      "6fq6\n",
      "6fq8\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
