{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python 3\n",
    "import re\n",
    "import csv\n",
    "\n",
    "#PATH = \"./\"\n",
    "PATH = \"/net/pan1/interactomes/pipeline/Interactome/Workflow/Interfaces/\"\n",
    "CHAIN_FILE = \"chains.csv\"\n",
    "PDB_LIST = \"histonesID.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#fils is a string with path to the file to be checked\n",
    "\n",
    "#RESULTS:\n",
    "#Returns 1 or 0 depending on file existence \n",
    "\n",
    "\n",
    "def file_check(file):\n",
    "    \n",
    "    try:\n",
    "        open(file, \"r\")\n",
    "        return 1\n",
    "    \n",
    "    except IOError:\n",
    "        print(\"Error: \" + file + \" does not appear to exist.\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#name is a string with the name of chain\n",
    "#typeCount is a 2-element list with the first one being an empty string and the second - 0 (iteger)\n",
    "\n",
    "#RESULTS:\n",
    "#Updates the typeCount array: the first element = general histone type(s); the second element = (should be) number of histones in chain\n",
    "\n",
    "def is_histone(name, typeCount):\n",
    "\n",
    "    if(re.search(r'histone', name, re.I)):\n",
    "       \n",
    "        if(not re.search(r'chaperone|ase|ing|hsh49|rep|alpha|thioredoxin|bombinin|chromosomal|nucleoprotein|envelope|snrnp', name, re.I)):\n",
    "            \n",
    "            typeCount[1] = 1 #adds the number of histones in chain  (should be changed to actual number of histones in chain!!!)\n",
    "\n",
    "            if(re.search(r'h2a', name, re.I)):\n",
    "                typeCount[0] += 'H2A|'\n",
    "                \n",
    "            elif(re.search(r'h2b', name, re.I)):\n",
    "                typeCount[0] += 'H2B|'\n",
    "                    \n",
    "            elif(re.search(r'h3', name, re.I)):\n",
    "                typeCount[0] += 'H3|'\n",
    "                    \n",
    "            elif(re.search(r'h4', name, re.I)):\n",
    "                typeCount[0] += 'H4|'\n",
    "                    \n",
    "            elif(re.search(r'h1', name, re.I)):\n",
    "                typeCount[0] += 'H1|'  \n",
    "                    \n",
    "            elif(re.search(r'h5', name, re.I)):\n",
    "                typeCount[0] += 'H5|'\n",
    "\n",
    "            elif(re.search(r'arch', name, re.I)):\n",
    "                typeCount[0] += 'archaeal histone|'\n",
    "                \n",
    "            else:\n",
    "                typeCount[0] += 'some histone|'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdbList is a text file with a header and one column PDB\n",
    "#files is a list\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#A list of absolute paths to either mapping files or interface files as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_files(pdbList, files, parameter):\n",
    "    \n",
    "    with open(pdbList, 'r') as pfh:\n",
    "        pfh.readline()\n",
    "        \n",
    "        if(parameter == 'mapping'):\n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2] \n",
    "                files.append(PATH + folder + '/' + line + '_chain_protein_mapping.tab')\n",
    "                \n",
    "        elif(parameter == 'interface'): \n",
    "            \n",
    "            for line in pfh:\n",
    "                line = line.strip()\n",
    "                folder = line[1] + line[2]\n",
    "                files.append(PATH + folder + '/' + line + '_atomic_contacts_5.0A.tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS: \n",
    "#pdb is a string with pdb id\n",
    "#parameter is a string, either 'mapping' or 'interface' depending on desired results\n",
    "\n",
    "#RESULTS:\n",
    "#An absolute paths to either mapping file or interface file as it is stored on local NCBI machines\n",
    "\n",
    "\n",
    "def get_file(pdb, parameter):\n",
    "    \n",
    "    if(parameter == 'mapping'):\n",
    "        folder = pdb[1] + pdb[2] \n",
    "        file = (PATH + folder + '/' + pdb + '_chain_protein_mapping.tab')\n",
    "        return file  \n",
    "        \n",
    "    elif(parameter == 'interface'): \n",
    "        folder = pdb[1] + pdb[2]\n",
    "        file = (PATH + folder + '/' + pdb + '_atomic_contacts_5.0A.tab')\n",
    "        return file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#cFile is tab-separated file with a header and 4 columns: pdb, chain, uniprot, name\n",
    "#dictionary is nested with the innermost dict being dictionary['pdb'] = {}\n",
    "\n",
    "#RESULTS: \n",
    "#The format of the end-product dictionary is: {pdb : {AlexChain: myChain|UNIPROT|name|type|process|function|organism|nucleosome(bool)|bindingPartner(bool)}}\n",
    "#Example: {1alq : {'G': 'E|P02302|Histone H3.3C|H3|1212|4141|human|1|0'}}\n",
    "\n",
    "\n",
    "def get_chain_dictionaries(cFile, dictionary): \n",
    "    \n",
    "    #with open(cFile, 'r') as cfh:\n",
    "        #cfh.readline()\n",
    "\n",
    "    histoneCount = {} #is used to count number of histones in a structure!!!!!!!\n",
    "\n",
    "    tempDict = {}\n",
    "    tempDict['pdb'] = {}\n",
    "\n",
    "    mappingFiles = [] \n",
    "    get_files(PDB_LIST, mappingFiles, 'mapping')\n",
    "\n",
    "\n",
    "    for file in mappingFiles:\n",
    "\n",
    "        try: #adds a pdb entry to the dict only if mapping file exists\n",
    "\n",
    "            with open(file, 'r') as mfh:\n",
    "                mfh.readline() #skips header\n",
    "                pdb = file.split('/')[-1].split('_', 1)[0]\n",
    "\n",
    "                for mLine in mfh:\n",
    "                    chainPair = mLine.split('\\t', 2)\n",
    "                    alexChain = chainPair[0]\n",
    "                    myChain = chainPair[1]\n",
    "\n",
    "                    if(pdb in tempDict):\n",
    "                        tempDict[pdb][alexChain] = myChain\n",
    "\n",
    "                    else:\n",
    "                        tempDict[pdb] = {alexChain : myChain}\n",
    "\n",
    "        except IOError:\n",
    "            pass\n",
    "            #print(\"Error: \" + mappingFile + \" does not appear to exist.\")\n",
    "\n",
    "\n",
    "    chains_file = csv.DictReader(open(cFile))  \n",
    "    for cLine in chains_file:\n",
    "    #for cLine in cfh: \n",
    "\n",
    "        #fields = cLine.strip().split('\\t')\n",
    "\n",
    "        #pdb = fields[0]\n",
    "        pdb = cLine[\"structureId\"].lower()\n",
    "        if(pdb in tempDict): #continues only if a mapping file exists\n",
    "            chain = cLine[\"chainId\"]\n",
    "            organism = cLine[\"source\"]\n",
    "            uniprot = cLine[\"uniprotAcc\"].lower()\n",
    "            name = cLine[\"uniprotRecommendedName\"]\n",
    "\n",
    "            histoneTypeAndCount = ['', 0]\n",
    "\n",
    "            is_histone(name, histoneTypeAndCount) #checks whether the name looks like a histone!!!!!!!!!\n",
    "\n",
    "            tempType = histoneTypeAndCount[0]\n",
    "            tempCount = histoneTypeAndCount[1]\n",
    "\n",
    "            #######################\n",
    "            if(tempCount): #if the chain is a [part of a] histone\n",
    "\n",
    "                if(pdb in histoneCount):\n",
    "\n",
    "                    if(tempType not in histoneCount[pdb]):\n",
    "                        histoneCount[pdb].append(tempType) #!!!!!!\n",
    "\n",
    "                else:\n",
    "                    histoneCount[pdb] = [tempType]       \n",
    "\n",
    "            try: #adds a chain entry to the dict only if there exists a corresponding chain in the mapping file\n",
    "                alexChain = list(tempDict[pdb].keys())[list(tempDict[pdb].values()).index(chain)]\n",
    "\n",
    "                if(pdb in dictionary):\n",
    "\n",
    "                    if(tempCount): #checks if chain is a histone!!!!\n",
    "                        dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + tempType + organism + '|' #!!!!\n",
    "\n",
    "                    else: #!!!!\n",
    "                        dictionary[pdb][alexChain] = str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + 'other|' + organism  + '|' #!!!!\n",
    "\n",
    "                else:\n",
    "\n",
    "                    if(tempCount): #checks if chain is a histone!!!!\n",
    "                        dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + tempType + organism + '|'} #!!!!\n",
    "\n",
    "                    else: #!!!!\n",
    "                        dictionary[pdb] = {alexChain : str(tempDict[pdb][alexChain]) + '|' + uniprot + '|' + name + '|' + 'other|' + organism + '|'} #!!!!\n",
    "\n",
    "            except ValueError:\n",
    "                #print(\"Error: \" + str(ValueError) + \", in \" + pdb)               \n",
    "                pass\n",
    "\n",
    "\n",
    "\n",
    "    for structure in list(dictionary): \n",
    "\n",
    "        if(structure in histoneCount):\n",
    "            uniqueHistoneNum = len(histoneCount[structure])\n",
    "            partnerFlag = 0\n",
    "\n",
    "            if(uniqueHistoneNum > 2): #checks if pdb has at least 3 different histones ~ is a nucleosome!!!!!!!\n",
    "\n",
    "                for chain in dictionary[structure]:\n",
    "                    chainFields = dictionary[structure][chain].split('|')\n",
    "\n",
    "                    chainType = chainFields[3]  ##\n",
    "\n",
    "                    dictionary[structure][chain] += 'nucleosome:1|' #!!!!!!\n",
    "\n",
    "                    if(partnerFlag == 0 and chainType == 'other'):\n",
    "                        partnerFlag = 1\n",
    "                        \n",
    "                if(partnerFlag == 0):\n",
    "                    #print(structure + '\\t' + 'nucleosome' + '\\t' + 'no')\n",
    "                    for chain in dictionary[structure]:\n",
    "                        dictionary[structure][chain] += 'bp:0'\n",
    "\n",
    "                else:\n",
    "                    #print(structure + '\\t' + 'nucleosome' + '\\t' + 'yes')\n",
    "                    for chain in dictionary[structure]:\n",
    "                        dictionary[structure][chain] += 'bp:1'\n",
    "\n",
    "            else: #!!!!!!\n",
    "\n",
    "                for chain in dictionary[structure]: #!!!!!\n",
    "                    chainFields = dictionary[structure][chain].split('|')\n",
    "\n",
    "                    chainType = chainFields[3]\n",
    "\n",
    "                    dictionary[structure][chain] += 'nucleosome:0|' #!!!!!! \n",
    "\n",
    "                    if(partnerFlag == 0 and chainType == 'other'):\n",
    "                        partnerFlag = 1\n",
    "\n",
    "                if(partnerFlag == 0):\n",
    "                    #print(structure + '\\t' + 'histone' + '\\t' + 'no')\n",
    "                    for chain in dictionary[structure]:\n",
    "                        dictionary[structure][chain] += 'bp:0'\n",
    "\n",
    "                else:\n",
    "                    #print(structure + '\\t' + 'histone' + '\\t' + 'yes')\n",
    "                    for chain in dictionary[structure]:\n",
    "                        dictionary[structure][chain] += 'bp:1'\n",
    "\n",
    "        else:\n",
    "            del dictionary[structure]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARAMETERS:\n",
    "#interfaceFiles is a list of strings containing names of interface files\n",
    "#chainDictionary is a dictionary produced by 'get_chain_dictionaries'\n",
    "#interfaceDictonary is a nested dictionary with the innermost dict being interfaceDictionary['uniprotPair'] = {}, where the values are lists of the next form [chain pair data, residue number, pdb IDs] \n",
    "#Example: 'P84233@P62799': {'44': ['A|P84233|Histone H3.2|h3|1@B|P62799|Histone H4|h4|1$E|P84233|Histone H3.2|h3|1@F|P62799|Histone H4|h4|1', 17, '1zla$q5cl']\n",
    "#note that data fields of a chain is separated by |, @ separates chain from binding partner chain, $ separates chain pairs and pdb structures\n",
    "#A|P84233|Histone H3.2|H3|Xenopus laevis|nucleosome:1|bp:1\n",
    "\n",
    "\n",
    "def residue_count(interfaceFiles, chainDictionary, interfaceDictionary):\n",
    "    \n",
    "    for file in interfaceFiles:\n",
    "        pdb = file.split('/')[-1].split('_', 1)[0] \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            with open (file, 'r') as ifh:\n",
    "                ifh.readline()\n",
    "             \n",
    "                with open('results.tsv', 'a') as rfh:\n",
    "                    \n",
    "                    for line in ifh:\n",
    "                        lineFields = line.split('\\t')\n",
    "\n",
    "                        chain1 = lineFields[0].split('_', 1)[0] # the split part treats biological assembly chains as separate chains ???\n",
    "                        chain2 = lineFields[4].split('_', 1)[0]\n",
    "\n",
    "                        fields1 = chainDictionary[pdb][chain1].split('|')\n",
    "                        fields2 = chainDictionary[pdb][chain2].split('|')\n",
    "\n",
    "                        uniprot1 = fields1[1]\n",
    "                        uniprot2 = fields2[1]\n",
    "\n",
    "                        type1 = fields1[3]\n",
    "                        type2 = fields2[3]\n",
    "                        nucleosome = int(fields1[5].split(':')[1])\n",
    "                        bp = int(fields1[6].split(':')[1])\n",
    "\n",
    "                        if(not nucleosome and bp and type1 != 'other' and type2 == 'other'):\n",
    "\n",
    "                            residue1 = lineFields[2]\n",
    "                            residue2 = lineFields[6]\n",
    "\n",
    "                            with open('hitdata.txt', 'r') as hfh:\n",
    "                                hfh.readline()\n",
    "\n",
    "                                for line in hfh:\n",
    "                                    fields = line.split('\\t')\n",
    "                                    uniprot = fields[0].split(' - ')[1]\n",
    "                                    start = int(fields[3])\n",
    "                                    end = int(fields[4])\n",
    "                                    domtype = fields[1]\n",
    "                                    name = fields[8]\n",
    "                                    if(uniprot2 == uniprot):\n",
    "                                        if(domtype == 'specific'):\n",
    "                                            if(int(residue2) >= int(start) and int(residue2) <= int(end)):\n",
    "                                                hfields = chainDictionary[pdb][chain1].split('|')\n",
    "                                                pfields = chainDictionary[pdb][chain2].split('|')\n",
    "                                                rfh.write(hfields[2] + '\\t' + hfields[3] + '\\t' + hfields[4] + '\\t' + residue1 + '\\t' + pfields[1] + '\\t' + pfields[2] + ', ' + name + '\\t' + pfields[4] + '\\n')\n",
    "                                                #print(hfields[2] + '\\t' + hfields[3] + '\\t' + hfields[4] + '\\t' + residue1 + '\\t' + pfields[1] + '\\t' + pfields[2] + '\\t' + pfields[4] + '\\t' + name)\n",
    "                                hfh.seek(0)\n",
    "\n",
    "\n",
    "                        if(not nucleosome and bp and type2 != 'other' and type1 == 'other'):\n",
    "\n",
    "                            residue1 = lineFields[2]\n",
    "                            residue2 = lineFields[6]\n",
    "\n",
    "                            with open('hitdata.txt', 'r') as hfh:\n",
    "                                hfh.readline()\n",
    "\n",
    "                                for line in hfh:\n",
    "                                    fields = line.split('\\t')\n",
    "                                    uniprot = fields[0].split(' - ')[1]\n",
    "                                    start = int(fields[3])\n",
    "                                    end = int(fields[4])\n",
    "                                    domtype = fields[1]\n",
    "                                    name = fields[8]\n",
    "                                    if(uniprot1 == uniprot):\n",
    "                                        if(domtype == 'specific'):\n",
    "                                            if(int(residue1) >= int(start) and int(residue1) <= int(end)):\n",
    "                                                hfields = chainDictionary[pdb][chain2].split('|')\n",
    "                                                pfields = chainDictionary[pdb][chain1].split('|')\n",
    "                                                rfh.write(hfields[2] + '\\t' + hfields[3] + '\\t' + hfields[4] + '\\t' + residue2 + '\\t' + pfields[1] + '\\t' + pfields[2] + ', ' + name + '\\t' + pfields[4] + '\\n')\n",
    "                                                #print(hfields[2] + '\\t' + hfields[3] + '\\t' + hfields[4] + '\\t' + residue2 + '\\t' + pfields[1] + '\\t' + pfields[2] + '\\t' + pfields[4] + '\\t' + name)\n",
    "                                hfh.seek(0)                            \n",
    "\n",
    "          \n",
    "                            \n",
    "        except (IOError, KeyError) as e:\n",
    "            #print(\"Error: \" + interfaceFile + \" does not appear to exist.\")\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    chainDictionary = {}\n",
    "    chainDictionary['chain'] = {}\n",
    "    get_chain_dictionaries(CHAIN_FILE, chainDictionary)\n",
    "    #for pdb in chainDictionary:\n",
    "     #   for chain in chainDictionary[pdb]:\n",
    "      #      print(pdb + '\\t' + chain + '\\t' + str(chainDictionary[pdb][chain]))\n",
    "\n",
    "    interfaceFiles = []\n",
    "    get_files(PDB_LIST, interfaceFiles, 'interface')\n",
    "\n",
    "    interfaceDictionary = {}\n",
    "    interfaceDictionary['uniprotPair'] = {}\n",
    "    residue_count(interfaceFiles, chainDictionary, interfaceDictionary)\n",
    "#     for pair in interfaceDictionary:\n",
    "#         for a in interfaceDictionary[pair]:\n",
    "#             print(pair + '\\t' + a + '\\t' + str(interfaceDictionary[pair][a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
